{"big-data-conference-uk-2015/public/schedule/detail/39559": {"room": "King's Suite - Balmoral", "title": "A taste of random decision forests on Apache Spark", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39559", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/157554"], "timing": "10:55\u201311:35 Thursday,  7/05/2015", "abstract": "Description\nApache Spark continues to gain momentum as the new processing paradigm for Apache Hadoop, and for the data scientist, it has a lot to like: natively distributed, REPL, Python APIs in addition to native Scala, and a library of machine learning algorithms, MLlib.\nSpark 1.2 includes an implementation of random decision forests, an important and popular ensemble classifier/regressor algorithm. This talk will introduce Spark, Scala, and random decision forests to the curious, and demonstrate the process of analyzing a real-world data set with them. The session will cover loading data and understanding the data set, and introduce ideas like training and test set evaluation, ensemble methods, feature types, and supporting concepts like impurity and entropy.\nAttendees will: \n- Become familiar with Spark basics using its Scala API\n- Understand the decision tree and random decision forest algorithms\n- See a simple, narrated data science workflow in action on a real data set"}, "big-data-conference-uk-2015/public/schedule/detail/42594": {"room": "King's Suite", "title": "Keynote with Christina Flounders", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42594", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/201891"], "timing": "9:55\u201310:05 Thursday,  7/05/2015", "abstract": "Christina Flounders, Bloomberg"}, "big-data-conference-uk-2015/public/schedule/detail/39796": {"room": "Blenheim Room - Palace Suite", "title": "It ain\u2019t what you do to data, it\u2019s what you do with it", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39796", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/1"], "timing": "11:45\u201312:25 Wednesday,  6/05/2015", "abstract": "Description\nIt\u2019s easy to talk about the cost-saving potential of big data, but it\u2019s harder to communicate and plan for the growth and agility that is the real success story behind famous data-driven companies.\nCreating value from data needs a new mindset.  It\u2019s hard to escape silos, whether they\u2019re technical or conceptual. To fully exploit new big data tools and architectures, we need a new way of thinking that frames data as a raw material of business. The answer is not to focus on the functional components\u2014what you do to data\u2014but on business outcomes and how they can be achieved\u2014what you do with data.\nTo fully exploit your data, you need to look at its lifecycle. By looking at the seven steps in the data value chain\u2014from discovery and ingest through to analysis and results\u2014we can analyze where to make investments in your data platform, and how to get early benefits while setting course for a modern data architecture.\nGetting value from data shouldn\u2019t require \u201cmagical thinking\u201d: this talk presents a framework for understanding and extracting value from your company\u2019s data."}, "big-data-conference-uk-2015/public/schedule/detail/39799": {"room": "St. James / Regents", "title": "Algorithm ethics: The inevitable subjective judgments in analytics", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39799", "topics": "Privacy, Law, & Ethics", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/177983", "/big-data-conference-uk-2015/public/schedule/speaker/153598"], "timing": "10:55\u201311:35 Thursday,  7/05/2015", "abstract": "Description\nEthics is how \u2018to decide in a morally right way\u2019. Algorithms are usually regarded as something deterministic and mathematical, not to contain ethics: Eratosthenes\u2019 sieve, for example, will give you all prime numbers up to a given maximum. Every other prime-checking algorithm will come to the same solution. A number is prime or not.\nBut there is a different kind of algorithm that is far more common in our daily life: calculations to find a solution for some task that other people might have done differently and with different outcomes. These algorithms contain value judgments, choices, or decisions made on how to deal with tasks according to social, cultural, or legal rules or personal persuasion. Obvious examples are credit scoring or pricing of a retail offer. However, there are a multitude of hidden ethical algorithms that are far more pervasive. When an ad network\u2019s targeting system selects which ads we see and which we don\u2019t, we might not find that too important. But a search engine deciding what it regards as relevant to us affects the information we see and what we miss. And medical images like MRIs might even affect our life with their many implicit parameters that are not visible to the physician.\nThere are three basic types of value judgments in algorithms: 1) Choosing a method, 2) Setting parameters, 3) Deciding how to deal with uncertainty and misclassification. All three judgments are quite regularly not made explicit. For many applications, the only way to understand these presumptions is to \u201copen the black box\u201d \u2013 hence to hack.\nWe will present some of these value judgments, discuss their consequences, and propose a cause to deal with them on a personal as well as on a business level."}, "big-data-conference-uk-2015/public/schedule/detail/40496": {"title": "Thursday Lunchtime BoF Tables (located in the Monarch Suite)", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40496", "topics": "Events", "speaker_urls": [], "timing": "12:25\u201313:45 Thursday,  7/05/2015", "abstract": "Birds of a Feather (BoF) discussions are a great way to informally network with people in similar industries or interested in the same topics.\nBoFs will happen during lunch on Wednesday, 6 May and Thursday, 7 May, and are located in the Monarch Suite.\nThis year\u2019s Industry Birds of a Feather discussion topics include:\n\nAdvertising & Marketing\nEnergy\nFinance\nGovernment & Policy\nHealthcare\nMedia & Entertainment\nRetail & eCommerce\nTelecommunications"}, "big-data-conference-uk-2015/public/schedule/detail/40497": {"title": "Wednesday Lunchtime BoF Tables (located in the Monarch Suite)", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40497", "topics": "Events", "speaker_urls": [], "timing": "12:25\u201313:45 Wednesday,  6/05/2015", "abstract": "Birds of a Feather (BoF) discussions are a great way to informally network with people in similar industries or interested in the same topics.\nBoFs will happen during lunch on Wednesday, 6 May and Thursday, 7 May, and are located in the Monarch Suite.\nThis year\u2019s Industry Birds of a Feather discussion topics include:\n\nAdvertising & Marketing\nEnergy\nFinance\nGovernment & Policy\nHealthcare\nMedia & Entertainment\nRetail & eCommerce\nTelecommunications"}, "big-data-conference-uk-2015/public/schedule/detail/42456": {"room": "Buckingham Room - Palace Suite", "title": "From Bigtable to HBase and back again - history and future", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42456", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/199825", "/big-data-conference-uk-2015/public/schedule/speaker/193517"], "timing": "16:15\u201316:55 Wednesday,  6/05/2015", "abstract": "Description\nGoogle developed Bigtable in 2004 to solve some of its critical big data problems, problems which many companies are facing today. The subsequent release of the technical details in the OSDI paper marked the beginning of the big data era, and sparked a wave of open source NoSQL databases including HBase, Cassandra, and an entire ecosystem of big data tools built around them. At Google, Bigtable continued to evolve, and has matured into a fully managed, almost infinitely scalable NoSQL database service.\nThis presentation will discuss some of our innovations on Bigtable in the past years, what we\u2019ve been working on with HBase, and include some announcements on where we\u2019re headed next! In addition, we\u2019ll bring up Emre Baran, CTO and co-founder of Qubit, to talk about their extensive use of HBase, and some new technologies and products they\u2019re building with us on Google Cloud Platform."}, "big-data-conference-uk-2015/public/schedule/detail/43744": {"room": "Windsor Suite", "title": "Modernize Your Data Management by Optimizing Your Data Warehousing Environments", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43744", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/205523", "/big-data-conference-uk-2015/public/schedule/speaker/192901"], "timing": "10:55\u201311:35 Wednesday,  6/05/2015", "abstract": "With the spiraling costs of Data Warehouses, and the need to capture more data from more sources, organisations are facing significant challenges in Big Data management. This session will look at Cisco\u2019s Data Warehouse Optimisation (DWO) Solution, and explores how it reduces ever-growing data warehouse management costs, whilst delivering a\u00a0greater variety and volume of data that can can be ingested and stored to derive new business insights.\nThis session is sponsored by Cisco"}, "big-data-conference-uk-2015/public/schedule/detail/40255": {"room": "St. James / Regents", "title": "Reproducible research with R and Shiny", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40255", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/148939", "/big-data-conference-uk-2015/public/schedule/speaker/197422"], "timing": "13:30\u201317:00 Tuesday,  5/05/2015", "abstract": "Description\nLearn how to combine the best ideas of reproducible research into a simple, easy to use workflow with R. Do you know that R can do more than analyze your data? R provides an easy way to report your results and make your research reproducible. This tutorial will teach you how to use R\u2019s reporting power with three R packages:\nThe Packrat package automatically captures the dependencies of your code when you run it, making sure that you can exactly reproduce results in the future. With Packrat, you can always rerun your script in its original computing environment, even if the packages used by your script have been replaced or updated.\nThe R Markdown package builds dynamic documents, presentations, and reports straight from your code. It combines the core syntax of markdown (an easy-to-write plain text format) with embedded R code chunks that are run so their output can be included in the final document. R Markdown documents are fully reproducible (they can be automatically regenerated whenever underlying R code or data changes) and completely dynamic (you can export an R Markdown document as an html, pdf, or MS Word file, or a slide show).\nThe Shiny package creates an interactive dashboard for your analyses. With Shiny, you can let readers use your reports to explore, customize, and stress test your results. Readers can modify parameters, update data sets, and make other changes that will immediately propagate through the models, tables, and plots of your report.\nTogether these packages create a reporting pipeline that makes it easy to reproduce your research and communicate your results in an engaging way. We will examine this pipeline and practice using it with a series of exercises and instructor-led examples."}, "big-data-conference-uk-2015/public/schedule/detail/42690": {"room": "Windsor Suite", "title": "No more standby read-only Hadoop disaster recovery sites", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42690", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/153419"], "timing": "13:45\u201314:25 Wednesday,  6/05/2015", "abstract": "It is now possible to achieve 100% utilization of globally-distributed Hadoop infrastructure by solving storage and compute challenges related to multi-data center deployments. The storage solution described uses Paxos-based, strongly consistent replication technology to continuously replicate data between Hadoop in multiple sites. The primary challenge is to keep data consistent in the face of network, process, and machine failures. Executing computation across sites is handled in a different manner, as it involves scheduling based on data availability and compute capacity availability. Example architectures using MapReduce and Hive will be explored in depth.\nSponsored by WANdisco"}, "big-data-conference-uk-2015/public/schedule/detail/39949": {"room": "King's Suite - Sandringham", "title": "Scaling SQL-on-Hadoop for BI", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39949", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/138654", "/big-data-conference-uk-2015/public/schedule/speaker/188660"], "timing": "14:35\u201315:15 Wednesday,  6/05/2015", "abstract": "Description\nSQL-on-Hadoop systems that support business intelligence (BI) use cases must be able to handle hundreds or even thousands of concurrent users. Existing SQL-on-Hadoop trade press focuses on single-user performance. This leaves a critical knowledge gap, as organizations consider using SQL-on-Hadoop to support BI applications involving a large number of concurrent users.\nThis talk discusses how you can scale your SQL-on-Hadoop system to a large number of concurrent users, and how to verify that your SQL-on-Hadoop system can support the current and future BI load. Specifically, we will talk about:\n- The impact of scaling cluster size and hardware\n- How to translate between cluster throughput and supported users\n- Growing your cluster with your data\n- How to verify performance before you go \u201cin production\u201d\nYou will never look at SQL-on-Hadoop performance the same way after this talk."}, "big-data-conference-uk-2015/public/schedule/detail/40006": {"room": "King's Suite - Sandringham", "title": "Scale out databases for CERN use cases", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40006", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193658"], "timing": "11:45\u201312:25 Wednesday,  6/05/2015", "abstract": "Description\nData generation rates are expected to grow very fast for some database workloads going into the second run of the Large Hadron Collider and beyond. In particular this is expected for data coming from controls, logging, and monitoring systems. Storing, administering, and accessing big data sets in a relational database system is in certain cases very demanding on the technology and therefore on cost. Thus, there is high interest in the CERN database community to find alternative solutions to relational database systems for storing and querying big data volumes with fast and scalable data access time. Scale-out database engines are an emerging and rapidly developing area. Recently a technical solution that has attracted attention is Cloudera Impala with columnar storage provided by Parquet on top of the Hadoop Distributed File System. This solution has the additional benefit of offering SQL as the main data access interface, which makes it easy to integrate with existing client applications. In this presentation we will discuss the results of our tests with the Cloudera Impala data querying  engine, including tests of data loading and integration with existing data sources, notably Oracle databases. We will report on query performance tests done with various data sets of interest at CERN, especially the accelerator log database."}, "big-data-conference-uk-2015/public/schedule/detail/39934": {"room": "King's Suite - Balmoral", "title": "What's there to know about A/B testing?", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39934", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/139926"], "timing": "14:35\u201314:55 Wednesday,  6/05/2015", "abstract": "Description\nThe hypothesis test is the standard tool for A/B testing. Taught in every introductory statistics class, its familiarity if often mistaken for simplicity. There are hosts of issues with running with a meaningful test, ranging from methodological \u2014 the nuts and bolts of collecting and interpreting data \u2014 to epistemological \u2014 questioning the very foundations of significance testing. In this talk I will discuss some of these issues. My aim is to inspire debate within the community, leading to a more nuanced view of A/B testing and better practices.\nThe first part of my talk will discuss the meaning and methodology of the classic hypothesis test. We\u2019ll cover fundamental assumptions behind A/B testing, type I and type II errors, and common mistakes like early stopping and misinterpreting results.\nThe second part will consider alternatives to the classic approach, confidence intervals and Bayesian methods, that still fit within the significance testing paradigm. I will describe how these alternatives give us additional information that allows more nuanced decision-making than the binary significant/not-significant approach often adopted with significance tests.\nFinally, I\u2019ll ask you to consider the basic underpinnings of significance tests. The goals of science (discovering truth) are not the goals of business (making money), and there are good reasons to look beyond the framework of significance testing in the business world. I\u2019ll describe scenarios where the fundamental assumptions of significance testing break down, and briefly discuss some of the alternatives approaches we can use in its place."}, "big-data-conference-uk-2015/public/schedule/detail/40060": {"room": "Blenheim Room - Palace Suite", "title": "How big data is redefining banking", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40060", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/190129"], "timing": "14:35\u201315:15 Wednesday,  6/05/2015", "abstract": "Description\nBig data technologies have become a fad in the industry, and big organizations are keen to ride the wave. But not many have succeeded in leveraging the true potential of big data. The challenges faced are not only technological but also in change management.\nAt Barclays, we have succeeded in building initial info-led propositions based on the ability to analyze terabytes of data in seconds. We overcame the challenges of bringing together structured and unstructured data by employing innovative solutions. Ankit Tharwani delivered an intelligent big data proposition, and the first big data capability for the bank, by cutting across layers and bringing together platforms at Barclays. He will talk of his journey of migrating from legacy tools to leverage the infinite potential of cutting-edge technologies to open doors to new use cases. Ankit will also talk about the technology vision for the bank, and how the strategic data landscape is evolving to make way for the likes of Hadoop."}, "big-data-conference-uk-2015/public/schedule/detail/39953": {"room": "Blenheim Room - Palace Suite", "title": "Data Strategy and the CDO", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39953", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/172046", "/big-data-conference-uk-2015/public/schedule/speaker/27740"], "timing": "13:45\u201314:25 Thursday,  7/05/2015", "abstract": "Description\nMost organizations now realize the benefits of exploiting data for growth. As the importance of having a strategy in place for how to derive full value from their data is sinking in, many organizations have added a chief data officer (CDO) to their executive team to help create and implement that strategy. But every organization is doing this a little bit differently \u2014 in terms of reporting structure, duties, and skillsets.\nThis talk will describe how a variety of industries and organizations are using CDOs and will make recommendations for best practices. It will cover:\n- Reclaiming \u201cdata strategy\u201d for business advantage\n- The emergence and main duties of a CDO\n- The skills required for an effective CDO\n- Cultivating a data-driven organization\nThis talk is meant for CEOs, CIOs, CTOs, would-be CDOs and anyone else with a stake in connecting top-level business strategy to projects and processes meant to derive value from data."}, "big-data-conference-uk-2015/public/schedule/detail/39954": {"room": "St. James / Regents", "title": "How (the Internet of) Things are turning the Internet upside down", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39954", "topics": "IoT/Machine Data", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/109262"], "timing": "16:15\u201316:55 Wednesday,  6/05/2015", "abstract": "Description\nJust when we thought the last mile problem was solved, the Internet of Things is turning the last mile problem of the consumer Internet into the first mile problem of the industrial Internet. Where previously we had servers moving bits to billions of consumers with almost perfect conservation of bits in the transmission from server to consumer, we are faced with a new patterns where billions of machines send measurements to servers.\nThis inversion impacts every aspect of the design of networked applications, from the switching hardware to the algorithms used to store and understand the data. I will show how to use existing Hadoop ecosystem tools such as Spark, Drill, and others, to deal successfully with this inversion. This will involve a tour of key algorithms, techniques, and tools used in such systems. This will be a practical talk which details real problems and real solutions."}, "big-data-conference-uk-2015/public/schedule/detail/39768": {"room": "St. James / Regents", "title": "The Internet of trains", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39768", "topics": "IoT/Machine Data", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193576"], "timing": "10:55\u201311:35 Wednesday,  6/05/2015", "abstract": "Description\nTrains today are complex systems consisting of many embedded subsystems, which operate together with the overall goal of delivering a high quality transportation service. The volume of data generated through logging of diagnostic events and sensor readings is huge, and can be an untapped source with potential for new business insights.\nThere are many issues involved in how to handle these data volumes and their underlying data types, such as XML, binary data, and custom logs. Then the data must be explored for relevant information, and the data pre-processing becomes important, i.e. aggregating sensor readings to meaningful time intervals.\nWhat analytics can be performed on this data, and what value is hidden in the patterns revealed by effectively storing and parsing this data?\nWe will explore these opportunities and discuss different approaches with the objective of reducing the cost of rolling stock fleet maintenance, minimizing train downtime, and improving fleet reliability.\nBy integrating diagnostic events and readings from sensors on trains with maintenance information, we have identified patterns that correlate with failures. We trained analytical models that we use to predict failures early, which allows predictive maintenance and optimized planning of service visits. Real uses cases are presented for predictive maintenance of trains as well as predictions of spare part consumption."}, "big-data-conference-uk-2015/public/schedule/detail/39952": {"room": "St. James / Regents", "title": "Using data for EVIL", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39952", "topics": "Privacy, Law, & Ethics", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/141417", "/big-data-conference-uk-2015/public/schedule/speaker/107765"], "timing": "11:45\u201312:25 Thursday,  7/05/2015", "abstract": "Description\nIt\u2019s hard to be good. It takes effort, and nobody ever appreciates it anyway. It\u2019s surprisingly easy to do evil when you have access to large volumes of data and an analytical mindset.\nThis session will give you a quick and easy guide to becoming an evil overlord of data without really trying. With (probably) anonymised examples from the real world, we show how ordinary data scientists have had a real impact on the world around them with very little effort.\nTo do this you need to move beyond simply not doing good, and enter the world of the evil data scientist. It\u2019s a world where advanced inferences from the data you gave away without a thought make privacy a thing of the past; where corporations use the cover of \u2018innovative disruption\u2019 to avoid laws; and where there is nothing more suspicious than a person who won\u2019t reveal their data.\nYou could use this talk to consider how to avoid ethical dilemmas, to develop ways to deal responsibly with data, or even to do good. But that would be perverse."}, "big-data-conference-uk-2015/public/schedule/detail/39951": {"room": "Blenheim Room - Palace Suite", "title": "Bridging big data with big health", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39951", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/191040"], "timing": "13:45\u201314:25 Wednesday,  6/05/2015", "abstract": "Description\nWhile the big data movement has been underway for many years, the healthcare industry lags behind in adopting and implementing innovative applications and algorithms. This slower adoption may be because healthcare data comprises all four Vs of big data \u2013 volume, velocity, variety, and veracity \u2013 as well as the veil of privacy. Regardless, there is a need and opportunity to facilitate moving health data to information more quickly to improve health outcomes.\nHealth informatics is a discipline concerned with transforming health-related data into information through the collection, transformation, management, and sharing of health data. The strength of health informatics research lies in the applications, data, and knowledge within each informatics group. However, constraints such as time and resources limit the potential speed for health discoveries.\nI will give specific examples from the last six years in working in health informatics, including: assembling the health data science team; building an analytics platform for research clinicians; and navigating government policy and internal politics. Additionally, suggestions on how to bridge the chasm between health and industry will be offered based on my experience with a few companies.\nIn summary, the talk will cover:\n   \u2013 Anatomy of health data \n   \u2013 Players in the health arena \n   \u2013 Driving forces in health data science \n   \u2013 Case studies: collaborations with industry and startups"}, "big-data-conference-uk-2015/public/schedule/detail/39819": {"room": "St. James / Regents", "title": "Visualizing the world's largest democratic exercise", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39819", "topics": "Privacy, Law, & Ethics", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193597"], "timing": "17:05\u201317:45 Thursday,  7/05/2015", "abstract": "Description\nAs part of an initiative to transform data journalism on television, CNN-IBN issued a challenge to the public: \u201cAsk us any question about the elections, and our anchors will answer it in real time.\u201d\nA large touch-screen was installed in their studio. The anchor transformed into an analyst, taking calls and answering them in real-time.\nThe visuals on the screen were created by Gramener, a data visualization firm. The focus was on simplicity (on TV, the audience needs to absorb information instantly), combined with flexibility (the anchor needs to answer the question instantly.)\nThe problem was coupled with data volume. The bulk of the 540 million votes was electronically counted in the first four hours between 8:00 am \u2013 12:00 noon, and results were streamed in real time. News became stale within a few seconds.\nThis talk is about the the design choices that went into the creation of the dashboard, the insights that came out of the data, and the technology that allowed serving over 10 million visitors on a single server that morning.\nThe lesson the talk aims to convey is: How to design a real-time visualization.\nHere are some links to earlier talks on this topic.\n\nVideo: The power of Big Data + Social in Governance\nVideo: Scaling real-time visualizations for elections 2014\nVideo: visualizing election data\n\n\nSlides: visualizing elections\nSlides: visualizing politics\nSlides: Scaling real-time visualizations for elections 2014\n\n\nBlog: Design of the 2014 election results page\nBlog: Tech behind the 2014 results page\nBlog: Optimising the 2014 election results page"}, "big-data-conference-uk-2015/public/schedule/detail/39816": {"room": "King's Suite - Balmoral", "title": "Fast > Perfect: Practical approximation examples for mobile app analytics using Spark Streaming", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39816", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/168002", "/big-data-conference-uk-2015/public/schedule/speaker/180777"], "timing": "16:15\u201316:55 Thursday,  7/05/2015", "abstract": "Description\nFor mobile games constant tweaks are the difference between success and failure. Product managers need instant access to the latest metrics, e.g. to see how an acquisition campaign is doing or how a change affects spending per user. Data and analytics must be available in real-time. However, calculating, for example, uniqueness or newness of a data point requires a list of seen data points \u2013 both memory-intensive and tricky when using real-time stream processing like Spark Streaming. Probabilistic data structures allow approximation of these properties with a fixed memory representation, and are very well suited for this kind of stream processing. Getting from the theory of approximation to a useful metric at a low error rate even for many millions of users is another story. In our talk we will look at practical ways of achieving this:\n\nWhich approximation we use for selection of useful metrics\nWhy we picked a specific probabilistic data structure\nHow we store it in Cassandra as a time series\nHow we implemented it in Spark Streaming (including example code to get started)"}, "big-data-conference-uk-2015/public/schedule/detail/39814": {"room": "Blenheim Room - Palace Suite", "title": "The curiosity advantage: the most important skill for data science", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39814", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193590"], "timing": "11:45\u201312:25 Thursday,  7/05/2015", "abstract": "Description\nWhen you search online for \u2018What makes a good data scientist\u2019, you\u2019ll find articles like: \u201cSix qualities of a great data scientist\u201d (Datascope Analytics, 2014), \u201cMost Important Trait For a Data Scientist? Curiosity\u201d (Advertising Age, 2013), \u201cGet the Right Data Scientists Asking the \u2018Wrong\u2019 Questions\u201d (Harvard Business Review, 2014).\nWhat all these articles emphasize is one of the most important skills for people working with data, curiosity. \u201cFundamentally, what sets a great data scientist apart is fierce curiosity \u2013 it\u2019s the X factor. You can teach the math and the analytical tools, but not the tenacity to experiment and keep working to arrive at the best question \u2013 which is virtually never the one you started out with.\u201d (Harvard Business Review, 2014).\nYet you find courses for math, analytics, and programming, but hardly any training for curiosity. Let\u2019s develop our curiosity with three short exercises in the session, and take them home and to our work:\nFind pleasure in uncertainty: New and uncertain activities make people happier and create more meaning than familiar routines. We\u2019ll re-train our brain to benefit from the pleasures of surprise and uncertainty. Living a life of curiosity is not about ignoring risk and anxiety. It\u2019s about being willing to do what we value, even in the face of risk and anxiety.\nTo question the question we\u2019re asking, we will:\n\nStep back\nNotice what others miss\nChallenge assumptions (including our own)\nGain a deeper understanding of the situation or problem at hand, through contextual inquiry\nTake ownership of a particular question\n\nBeginner\u2019s mind: \u201cIn the beginner\u2019s mind there are many possibilities, but in the expert\u2019s there are few.\u201d ~ Shunryu Suzuki\nWe\u2019ll do a 4 minute mindfulness exercise to rediscover our beginner\u2019s mind.\nGrowing our curiosity will not only help us in our work, but also in our personal life. Being curious is about recognizing novelty and seizing the pleasures and meaning they offer us. With our new curiosity, we will explore, discover, and grow."}, "big-data-conference-uk-2015/public/schedule/detail/39810": {"room": "King's Suite - Sandringham", "title": "How Goldman Sachs is using knowledge to create an information edge", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39810", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193595"], "timing": "10:55\u201311:35 Thursday,  7/05/2015", "abstract": "Description\nGoldman Sachs is taking a knowledge-driven approach to our big data strategy. Wherever possible, we are leveraging open standards and big data technologies to build our next generation data platform for the firm. In this presentation, we will describe how Goldman represents knowledge through modeling and leverages its models to transform data into information. We will also describe the technology stack and development approach being leveraged.\nIn the Goldman approach, authoritative raw data sources are stored in an enterprise data lake in Hadoop, stored in HDFS. To represent our knowledge domains, Goldman Sachs has developed an enterprise ontology representing its business concepts. The upper ontology is represented in OWL format and describes class structures and data transformation rules. These rules are then leveraged in a custom-developed Hadoop process to transform data into semantically consistent information in RDF format. The assertions and higher-order concepts from the lower ontology are leveraged to generate the rule set on the transformed data, creating \u201cBig Graphs\u201d consisting of, in some cases, billions of nodes and edges\nIn the presentation, we will highlight one significant business use case where we are using Big Graphs and graph analytics. We will also describe how the approach to information derivation is leveraged in analytics that can be used to gain business advantage."}, "big-data-conference-uk-2015/public/schedule/detail/42407": {"room": "King's Suite - Balmoral", "title": "Startup Showcase", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42407", "topics": "Events", "speaker_urls": [], "timing": "18:00\u201319:30 Tuesday,  5/05/2015", "abstract": "A new generation of businesses is betting that data-driven products can give them the edge. From efficient marketplaces to frictionless transactions, from better customer interaction to prescient predictions, from platforms that can mine vast troves of data instantly to catalogs of information available for sale, the startup ecosystem loves big data.\n\n\n\nStartups that put data first aren\u2019t just able to adjust faster and find their product and market better. They\u2019re also reconsidering aging industries and ailing infrastructure, upending incumbents and breaking down barriers to entry.\n\nStartup Showcase returns to Strata + Hadoop World in London 2015. It\u2019s a chance for founders to hone their pitch, meet investors, and bounce big idea off the industry\u2019s movers and shakers.\nOur team of investors, entrepreneurs, and industry analysts will select 10 leading big data startups from all the submissions we receive. These 10 firms will have a chance to present their technologies and tell their stories live at the Startup Showcase.\nStartup Showcase Finalist Companies\n\nBig Boards\nTrakker Solutions Ltd\nScaled Risk\nDataLion\nbrytlyt\nModgen\nTeraki\nDatumize\nWaterline Data\nOpenSensors"}, "big-data-conference-uk-2015/public/schedule/detail/39892": {"room": "King's Suite - Balmoral", "title": "Untangling influence and desire: Visual analysis of massive graph data", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39892", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/155181", "/big-data-conference-uk-2015/public/schedule/speaker/187615"], "timing": "17:05\u201317:45 Thursday,  7/05/2015", "abstract": "Description\nNode and link graphs are rapidly becoming key to analyzing and leveraging big data. Some graph-theoretic problems can be completely automated (e.g. recommender systems), but other applications such as community detection, fraud analysis, or market evolution are challenging to fully automate and require human interaction with graphs for exploratory analysis. Visualization harnesses the power of human perception to quickly identify patterns and form new hypotheses. By using node-link diagrams, we can reveal important relationships and structures in graph data.\nHowever, tools and technologies for visualizing massive graphs remain elusive. Visualizing graphs with the goal of revealing communities and relationships is challenging on a single machine, and the tangled visualization of results, even if achieved, is often impossible to navigate and make sense of. Further, analysis is an iterative process of data exploration and hypothesis-testing, requiring tools that support interactive exploration.\nIn this session we will demonstrate how open source big data and \u201cbig visualization\u201d technologies can be used to explore and make sense of massive graphs in an interactive process. The approach visualizes all the data, rather than samples or summaries, which lose valuable information. Applications such as analysis of social networks, customer purchase history, doctor referrals, and brain neural networks will be shown using open source tools that leverage Hadoop, Apache Spark, GraphX, and HBase for distributed computation and storage. Starting with distributed hierarchical graph clustering and layout algorithms, and employing a \u201cGoogle Maps\u201d style approach to rendering, navigation, and interaction, we will show how cluster computing and tile-based approaches can be used to gain insights from graphs of big data."}, "big-data-conference-uk-2015/public/schedule/detail/42409": {"room": "Offsite", "title": "Data After Dark: Pub Crawl", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42409", "topics": "Events", "speaker_urls": [], "timing": "19:15\u201321:15 Wednesday,  6/05/2015", "abstract": "Sponsored by:\n\n\n\n\n\nNote: This event is open to Strata + Hadoop World attendees only \u2014 bring your conference badge to get in.\nDon\u2019t miss the social highlight of Strata + Hadoop World: Data After Dark!\nMix and mingle with fellow attendees in the London neighborhood of Marylebone, host of the first Data After Dark: Pub Crawl. Marylebone offers what so many London neighborhoods cannot: a village feel coupled with urban convenience. Within this most desirable neighborhood, there are a vast array of outstanding restaurants & pubs, surrounded by some of the city\u2019s quietest nooks, crannies and cobbled streets.\nWe have chosen a few of these locations off Edgware & Crawford Place to experience all of what is great to eat and drink in Marylebone: The Chapel, The Larrik, The Grand Union, and Lord Wargrave."}, "big-data-conference-uk-2015/public/schedule/detail/40024": {"room": "King's Suite - Balmoral", "title": "Deploying machine learning in production", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40024", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/169590", "/big-data-conference-uk-2015/public/schedule/speaker/171326"], "timing": "13:45\u201314:05 Wednesday,  6/05/2015", "abstract": "Description\nPredictive applications unlock tremendous value for businesses through intelligent use of data. From personalized recommenders, targeted advertising, to customer churn prediction and influence analysis, predictive applications can enhance the customer experience and increase business revenue. In order to make decisions such as which ad to show to which user, what items to recommend, and which customers are most likely to churn, these smart apps rely on sophisticated analysis machine learning algorithms and models. Machine learning techniques are powerful, but building and deploying such models require a lot of care and expertise.\nWith a new generation of tools, it is possible to build such applications with a minimal amount of algorithm expertise. However, one must know how to evaluate, test, and track the performance of these machine learning models over time. This talk engages potential application builders on topics such as common evaluation metrics, A/B testing set up, tracking model performance, tracking usage via real-time feedback, and updating models. The talk will go into details on how to read the tea leaves of model training and prediction output, and understand \u201cdistribution drift.\u201d We will also show practical demonstrations of these ideas using GraphLab Create and other open-source tools."}, "big-data-conference-uk-2015/public/schedule/detail/42678": {"room": "King's Suite", "title": "Keynote with Cait O'Riordan", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42678", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/196005"], "timing": "9:35\u20139:45 Wednesday,  6/05/2015", "abstract": "Cait O\u2019Riordan, VP of product, music, and platforms, Shazam"}, "big-data-conference-uk-2015/public/schedule/detail/42679": {"room": "King's Suite", "title": "BT Featured Keynote", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42679", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/168490"], "timing": "9:05\u20139:15 Thursday,  7/05/2015", "abstract": "In this session, Phill Radley (BT Chief Data Architect) gives an overview of BT\u2019s internal multi-tenant hadoop platform. He explains  their first production use case (master data management of BT UK Business Customer data) and gives a flavour of their use case pipeline."}, "big-data-conference-uk-2015/public/schedule/detail/39579": {"room": "Buckingham Room - Palace Suite", "title": "Apache Spark: The faster new execution engine for Apache Hive", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39579", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/177668", "/big-data-conference-uk-2015/public/schedule/speaker/202946"], "timing": "10:55\u201311:35 Wednesday,  6/05/2015", "abstract": "Description\nApache Hive has become de facto standard for batch-oriented SQL workloads in the Hadoop ecosystem. With its open architecture and backend neutrality, Hive queries can currently run on MapReduce and Tez. However, Apache Spark as an open-source data analytics cluster computing framework has gained significant momentum recently, and marrying the two\u2014that is, providing a new execution engine to Hive\u2014has many benefits for Spark users as well Hive users.\nThe Hive on Spark initiative (HIVE-7292) is probably the most-watched project in Hive, with 120+ watchers. The effort has attracted developers both from communities around the world, and from vendors such as Intel, IBM, Cloudera, and MapR.\nThis presentation will talk about the motivation, design principles, architecture, challenges, and current status of the project followed by a live demo."}, "big-data-conference-uk-2015/public/schedule/detail/42671": {"room": "King's Suite", "title": "Bigtable\u2019s next big step", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42671", "topics": "Keynotes, \r\n\t\t\r\n\t\t\tSponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/199825"], "timing": "9:50\u20139:55 Wednesday,  6/05/2015", "abstract": "At Google, few things are so pervasive as Bigtable, the famous wide-column NoSQL database. It lies behind nearly every major Google product (Gmail, YouTube, Google Analytics), with its own class of internal memes, and a resource footprint unmatched anywhere else in the world. In the vibrant OSS community it is the forebear for a whole class of extraordinarily popular projects, including HBase, Cassandra,  Accumulo, and Hypertable. This battle-hardened, embarrassingly-powerful system has seen constant improvement over the last 10 years and is about to take a brand new leap in its evolution.\nSponsored by Google"}, "big-data-conference-uk-2015/public/schedule/detail/42672": {"room": "King's Suite", "title": "Hadoop: It\u2019s as easy as riding a bike", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42672", "topics": "Keynotes, \r\n\t\t\r\n\t\t\tSponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/146120"], "timing": "9:35\u20139:40 Thursday,  7/05/2015", "abstract": "Join SAS\u2019s Tamara Dull as she compares bike riding to current trends in big data adoption and explains why newer technologies like Hadoop aren\u2019t always to blame.\nSponsored by SAS"}, "big-data-conference-uk-2015/public/schedule/detail/42673": {"room": "King's Suite", "title": "Connected Car \u2013 World Record Race", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42673", "topics": "Keynotes, \r\n\t\t\r\n\t\t\tSponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/205398"], "timing": "9:40\u20139:45 Thursday,  7/05/2015", "abstract": "As the internet of things and connected car programs across the globe gain momentum and broaden in scope, check out this world record attempt; racing from North Cape, Norway to Cape Agulhas, South Africa.  HP monitored and analyzed sensor outputs from our team in their Volkswagen Touareg along with climate, social and other environmental data with some interesting results.  And one connected car crash.\nSponsored by HP"}, "big-data-conference-uk-2015/public/schedule/detail/42851": {"room": "Blenheim Room - Palace Suite", "title": "Designing with data: A human-centered approach to data-driven design", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42851", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/203397"], "timing": "16:15\u201316:55 Thursday,  7/05/2015", "abstract": "IDEO\u2019s Hybrid team was formed to apply the human-centered techniques from IDEO\u2019s product design process to the world of data and analysis. By starting with interviews, ideation sessions, and other processes, we gain understanding of business and organizational needs before designing experiments and delving into the data analysis process. Extensive use of surveys complements the quantitative processes associated with operational, social media, sensor, and other data types to gain actionable insights. To ensure results and insights are well communicated to clients, we use storytelling and visualization to highlight the most important findings for decision making."}, "big-data-conference-uk-2015/public/schedule/detail/42562": {"room": "Blenheim Room - Palace Suite", "title": "Data-driven retailing in the modern world", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42562", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/200638"], "timing": "17:05\u201317:45 Wednesday,  6/05/2015", "abstract": "Description\nThe key to success of every retailer is to know and understand the customer. The big data revolution presents both challenges and opportunity. Retail data is often stored in silos, so it\u2019s difficult to correlate data about customer purchases, marketing campaign results, and online browsing behaviour.\nBy using big data technologies, retailers can analyse both structured and un-structured data in order to focus sharper lenses on consumer behaviour. This can drive decision-making across the business from ranging, to stock forecasting, to CRM and beyond.\nThis session will look at the journey M&S have been on and have ahead in using data to help turn it from a traditional British high street retailer to a global, multi-channel retailer. It will explore the impact on culture, technology, ways of working, and capabilities needed to drive the change."}, "big-data-conference-uk-2015/public/schedule/detail/40740": {"room": "St. James / Regents", "title": "The internet of everything: Creating programmable cities, cars, and homes", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40740", "topics": "IoT/Machine Data", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/158042"], "timing": "13:45\u201314:05 Wednesday,  6/05/2015", "abstract": "Description\nWe are only scratching the surface about the scale of transformation that the Internet of Things will bring.\nUsing examples of Internet of Things applications such as cities, cars, and homes, we will explore the challenges and advantages of processing a large number of disparate sensors. We will explore the advantages and tradeoffs of technical design decisions. We will look at the complete life-cycle of data from a sensor from the firmware level, to the network and the cloud.\nThings we will talk about in the above mentioned:\n- The advantages and disadvantages of various network protocols for cities, cars, and homes\n- The lack of semantics for sensors and the problems that this causes for interoperability\nI will run through examples of the positive impacts we are seeing when people are able to freely access real-time data and plug these into new and existing services."}, "big-data-conference-uk-2015/public/schedule/detail/39807": {"room": "King's Suite - Balmoral", "title": "Improving feature engineering in the lab and production with Ivory", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39807", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193273"], "timing": "11:45\u201312:25 Wednesday,  6/05/2015", "abstract": "Description\nFeature engineering is a critical and time-consuming activity in the development and deployment of any modeling pipeline. It is also exacerbated as data science teams seek to incorporate new data sources into their pipelines that are at a scale far larger than previously employed. Furthermore, the transition to production environments is littered with complexity as these pipelines are exposed to the dynamic, and fragile, world of ongoing data feeds, data corrections, and evolving data models.\nIn this talk we will introduce Ivory, a new open-source, Hadoop-based data store that seeks to address these challenges. Ivory is a scalable and extensible data store for storing facts and extracting features. It is optimised specifically for the feature engineering stages of modelling pipelines, simultaneously simplifying and adding rigour to them.\nThis session will walk through an example of how Ivory can be used in the typical data scientist\u2019s workflow, and then how that extends to migrating pipelines into production. It will impart all of the basic concepts of Ivory such as repositories, the dictionary, its fact-based data model, and virtual features. It will also demonstrate the benefits of Ivory being an immutable data store and the unique opportunities that creates."}, "big-data-conference-uk-2015/public/schedule/detail/43645": {"room": "Windsor Suite", "title": "Purpose Built Analytics Infrastructure, Intel and HP Powering Performance at Scale", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43645", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/187069", "/big-data-conference-uk-2015/public/schedule/speaker/122916"], "timing": "14:35\u201315:15 Wednesday,  6/05/2015", "abstract": "While the return on investment from the successful use big data analytics has been documented extensively, investment in infrastructure can still be a point of concern. In particular, due to the quickly changing nature of the technology landscape, the main worry is how infrastructure purchased today can adapt with these new usage patterns and workloads of tomorrow. The rise of new in-memory processing frameworks like Apache SPARK is just one example of new disruptions that are driving a reevaluation of general purpose type infrastructure to one that is more purpose built for analytics while still retaining flexibility to adapt. Join Intel and HP as they discuss innovations in new server designs powered by Intel Architecture that are enabling customers to adopt and grow their big data environments with confidence.\nSponsored by Intel"}, "big-data-conference-uk-2015/public/schedule/detail/39777": {"room": "King's Suite - Sandringham", "title": "Big telco GIS on Hadoop", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39777", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/187196"], "timing": "17:05\u201317:45 Thursday,  7/05/2015", "abstract": "Description\nData transfer is one of the most pressing problems facing companies in the telecom industry today. As data requirements grow by the month, so do costs. To a certain point, huge data processing has been sufficient for SKT. But huge increases in requirements brought about by more sophisticated smartphones have started to create serious business bottlenecks, with the need for near real-time analytics on the Hadoop load of petabytes of data. In this presentation, Yousun Jeong and Yongjin Choi will detail how SKT dealt with this problem; how to provide geo-analytic functions for data scientists with Spark and IPython Notebook; how to visualize geodata with more efficiency; and how Spark and Tajo YARN are used for high-speed large enterprise geodata processing.\n1) Business requirement, challenges\n  -Why GIS analysis platforms based on Hadoop are needed for increased data\n  -Processing performance requirements for data analysis and data processing methods\n2) Real-time data processing and visualization\n  \u2013 Explain why we should choose Spark for real-time data processing\n  \u2013 Illustrate a process of data mashups and visualization for data analysts\n3) Performance issues, resolution and troubleshooting\n  \u2013 Evolve performance optimization and measure point of performance\n  \u2013 Introduce Python modules used for spatial algorithms and analysis\n4) System architecture and demo\n  \u2013 Case study in real market: the platform application at SKT, the number one telecom company in Korea; in the view of data collecting, processing, and analysis."}, "big-data-conference-uk-2015/public/schedule/detail/39776": {"room": "King's Suite - Balmoral", "title": "Hunting criminals with hybrid analytics, semi-supervised learning, and agent feedback", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39776", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/140636", "/big-data-conference-uk-2015/public/schedule/speaker/171362"], "timing": "13:45\u201314:05 Thursday,  7/05/2015", "abstract": "Description\nFraud detection is a classic adversarial analytics challenge: As soon as an automated system successfully learns to stop one scheme, fraudsters move on to attack another way. Each scheme requires looking for different signals (i.e. features) to catch; is relatively rare (one in millions for finance or e-commerce); and may take months to investigate a single case (in healthcare or tax, for example) \u2013 making quality training data scarce.\nThis talk will cover, via live demo and code walk-through, the key lessons we\u2019ve learned while building such real-world software systems over the past few years. We\u2019ll be looking for fraud signals in public email datasets, using IPython and popular open-source libraries (scikit-learn, statsmodel, nltk, etc.) for data science and Apache Spark as the compute engine for scalable parallel processing.\nWe will iteratively build a machine-learned hybrid model \u2013 combining features from different data sources and algorithmic approaches, to catch diverse aspects of suspect behavior:\n\nNatural language processing: finding keywords in relevant context within unstructured text\nStatistical NLP: sentiment analysis via supervised machine learning\nTime series analysis: understanding daily/weekly cycles and changes in habitual behavior\nGraph analysis: finding actions outside the usual or expected network of people\nHeuristic rules: finding suspect actions based on past schemes or external datasets\nTopic modeling: highlighting use of keywords outside an expected context\nAnomaly detection: Fully unsupervised ranking of unusual behavior\n\nThis talk assumes basic understanding of these data science tools, so we can focus on their applicability for this use case and on how they complement each other.\nApache Spark is used to run these models at scale \u2013 in batch mode for model training and with Spark Streaming for production use. We\u2019ll discuss the data model, computation, and feedback workflows, as well as some tools and libraries built on top of the open-source components to enable faster experimentation, optimization, and productization of the models."}, "big-data-conference-uk-2015/public/schedule/detail/40349": {"room": "St. James / Regents", "title": "Introduction to machine learning with IPython and scikit-learn", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40349", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/122636"], "timing": "9:00\u201312:30 Tuesday,  5/05/2015", "abstract": "Scikit-learn is a versatile machine learning library for Python that blends well with the NumPy and SciPy ecosystems, and is used by a growing user base of academic researchers as well as data scientists and engineers in the tech industry.\nIPython with its notebook interface is an interactive programming environment that is particularly well suited for data exploration, modeling, and sharing of analysis results, notably via nbviewer.ipython.org.\nThe objective of this tutorial is to get acquainted both with machine learning concepts in general and the pydata ecosystem in particular.\nThe session will cover the following topics:\n\nHow to extract a machine learning-friendly representation of raw data (feature extraction)\nHow to train various machine learning models such as logistic regression, support vector machines, and randomized ensembles of decision trees\nHow to evaluate the predictive accuracy of a model and detect overfitting\nHow to automatically tune the model parameters from data."}, "big-data-conference-uk-2015/public/schedule/detail/39963": {"room": "Buckingham Room - Palace Suite", "title": "Taming the firehose: Build analytics over 45 billion tweets using Elasticsearch and Spark", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39963", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193655", "/big-data-conference-uk-2015/public/schedule/speaker/193426"], "timing": "11:45\u201312:25 Thursday,  7/05/2015", "abstract": "Description\nEvery day, over half a billion tweets are generated. And processing them for analytics can seem to be a Herculean task. We at Microsoft deal with such social data sets on a daily basis, and in this talk we share our experiences building a real time search, analytics, and trends pipeline over social data, with the power of Elasticsearch, Azure, and Spark.\nWhile Elasticsearch is highly scalable, fine tuning the architecture to respond in under 900 milliseconds for 45 billion documents (while indexing) is still a tough task. We will discuss several aspects including design of search cluster, experimentation setup for performance tuning, learnings from cloud services, fault tolerance, monitoring, customer facing APIs, lowering costs and other best practices, to get the most out of your hardware.\nNext, we talk about enabling analytics over this data using stream processing. We will discuss annotating tweets with natural language processing tools and text-based classifiers, doing temporal analytics, and eventually building applications like topical trend generation (for example, TV show trends for Xbox). Such a case study will be a good example of bridging the gap between the fields of data science and data engineering."}, "big-data-conference-uk-2015/public/schedule/detail/39966": {"room": "Buckingham Room - Palace Suite", "title": "Say goodbye to batch", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39966", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193653"], "timing": "16:15\u201316:55 Thursday,  7/05/2015", "abstract": "Description\nHistory has shown the limitations of existing streaming systems with respect to reliability, flexibility, and ease of use. The industry has responded in turn with the Lambda Architecture, a clever confederation of batch and streaming systems that provides low-latency, eventually-correct results, while maintaining the ability to respond to changes in upstream data. Lambda proponents have long argued that it\u2019s not possible to have all these things at once within a single streaming system. We respectfully disagree. :-)\nWe believe it is possible to build a streaming system you can rely on, making the Lambda Architecture unnecessary. In this talk, I\u2019ll cover:\n\nThe fundamental differences between batch and streaming, and how the Lambda Architecture combines them to great effect.\nA survey of the ways streaming systems can be used to process data, including uses currently filled by the Lambda Architecture.\nA detailed look at the problems of correctness and changes in upstream data when relying solely on a streaming system.\nThe APIs and semantics we provide in Google Cloud Dataflow that make it tractable to solve those problems within a single streaming system, along with best-practice examples for dealing with real-world use cases.\n\nThis talk is, at the same time, both high-level and quite technical. There are varying opinions about what streaming is, and this talk attempts to give an overview of what the different existing approaches are. It then covers in detail the streaming use case that no other general streaming system has yet conquered: that of providing low-latency, correct results with the flexibility to adjust to changes in source data, all at a massive scale. We hope to provide the audience an understanding of the issues they might face in building standalone streaming pipelines, regardless of the architecture used, with an eye toward the features of Google Cloud Dataflow that make it particularly well-suited to that problem domain."}, "big-data-conference-uk-2015/public/schedule/detail/39967": {"room": "Blenheim Room - Palace Suite", "title": "The data strategy revolution: building an in-house data insights lab", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39967", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/148403", "/big-data-conference-uk-2015/public/schedule/speaker/187700", "/big-data-conference-uk-2015/public/schedule/speaker/134499"], "timing": "10:55\u201311:35 Thursday,  7/05/2015", "abstract": "Description\nWhen John Miller was doing data strategy work as a partner at Accenture, he would bring in Nate Shetterley\u2019s team at Accenture\u2019s Technology Labs to help make concepts practical for his clients. The Labs could pull together open source technology and open data, create a visualization, and mock up a prototype in a few weeks, leaving clients wowed by the power of data science and visualization to help them understand the questions at hand.\nIt became clear to Nate that this was something many Accenture teams were missing \u2013 a small innovation group that could focus on cutting-edge data and technologies to help bring concepts to life. He invited John to join him at Labs, to help develop this idea and make it available to other teams at Accenture.\nIt wasn\u2019t long before they realized that this is in fact what most clients were missing \u2013 an in-house data exploration capability. In essence, clients wanted their own Technology Labs to help them develop and apply data insights in real time. John and Nate brought Hallie Benjamin over to the Labs to help them build this concept more concretely, and prove to both Accenture and its clients that they had been thinking about data strategy all wrong.\nIn this talk John, Nate, and Hallie will explain their perspective on the existing approach to data strategy, and how organizations must shift to incorporate a dedicated technology innovation lab to pave the way for exploration of new data frontiers."}, "big-data-conference-uk-2015/public/schedule/detail/40341": {"room": "King's Suite - Balmoral", "title": "Scalable machine learning", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40341", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/180950"], "timing": "11:45\u201312:25 Thursday,  7/05/2015", "abstract": "Description\nBig Data platforms like Hadoop have matured significantly in the past few years. Now it is possible to deal with huge amounts of data in a scalable fashion both for storage and processing. Newer projects like Apache Spark overcome some of the issues of MapReduce-based batch processing, allowing users to implement complex learning and data analysis methods.\nHowever, truly scalable implementations of complex data analysis algorithms are still challenging. So far, such approaches have relied less on massive parallelization than on clever algorithmic tricks leading to approximate and fast algorithms. Algorithms like stochastic gradient descent that can deal with huge amounts of data, however, are notoriously hard to parallelize.\nIn this talk, I will review classic approaches to large scale learning as well as some of the recent developments in the field like Google\u2019s DistBelief, an approach to parallelize deep learning using concepts like parameter servers; or the use of approximate algorithms like Count-Min-Sketches as building blocks to create fast and scalable machine learning algorithms. The talk will thus attempt to identify the key concepts that will guide the field in the coming years."}, "big-data-conference-uk-2015/public/schedule/detail/42669": {"room": "King's Suite", "title": "Hadoop 2015: What we\u2019ve learned in 5 years", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42669", "topics": "Keynotes, \r\n\t\t\r\n\t\t\tSponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/202665"], "timing": "9:25\u20139:35 Wednesday,  6/05/2015", "abstract": "After five years of enterprise adoption, Hadoop is now a critical data asset in your analytic and data platform strategy. Some companies, however, are struggling with making Hadoop work for their enterprise needs. This presentation will discuss how Think Big, a pioneer in big data services with Hadoop, is helping a global organization utilize multi-petabyte Hadoop clusters to drive tangible business results. Highlights in this presentation will include how this company is using best practices for data ingestion across multiple manufacturing facilities in Asia and the US, utilizing robust patterns for handling data quality, metadata management, pipelining, buffering, and security to establish Hadoop as an enterprise data lake. Working with more than 100 clients on Hadoop projects, Think Big, a Teradata Company, will describe other enterprise design patterns and successful organizational models used by their clients, and how to avoid the pitfalls associated with designing, managing, and scaling your enterprise data lake.\nSponsored by Teradata"}, "big-data-conference-uk-2015/public/schedule/detail/39882": {"room": "Blenheim Room - Palace Suite", "title": "Where the rubber meets the road: Decision-making based on data", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39882", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193626"], "timing": "10:55\u201311:35 Wednesday,  6/05/2015", "abstract": "Description\nI\u2019ll present a collection of case studies for:  \n- Entering a completely data-free environment at EMI Music, which eventually got written up as a leader in big data analytics by The Economist.  \n- Experiencing the traditional strategy consulting business, where the work can involve creating first-party data as well as slicing and dicing the client\u2019s own data.  \n- Working with a world-class data organization at American Express that had some analysis-paralysis and perfectionist tendencies.  \n- Joining a point-of-sale startup with extremely specific and narrow data, and how I\u2019m making that more valuable through mash-ups at ShopKeep.\nAttendees will learn:  \n- Where to focus their analytic efforts to be relevant to business owners\n- Which shortcuts to take, and which ones not to take\n- When to use a more iterative vs waterfall approach to implementing predictive models\n- How to evaluate third-party data and explain that back to business owners"}, "big-data-conference-uk-2015/public/schedule/detail/42667": {"room": "King's Suite", "title": "Keynote with Julie Meyer", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42667", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/202557"], "timing": "9:55\u201310:05 Wednesday,  6/05/2015", "abstract": "Julie Meyer, chairman, CEO, and founder, Ariadne Capital"}, "big-data-conference-uk-2015/public/schedule/detail/43657": {"room": "Windsor Suite", "title": "A modern, flexible approach to Hadoop implementation, incorporating innovations from HP Vertica & IDOL", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43657", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/204628"], "timing": "14:35\u201315:15 Thursday,  7/05/2015", "abstract": "HP is committed to open source and has integrated Hadoop into the core of our Big Data platform, solutions and services. We will introduce the new HP Big Data Reference Architecture with the brand new HP ProLiant Apollo servers designed for Big Data and Hadoop, HP\u2019s software solutions for Hadoop, and a series of services that will accelerate your adoption of Hadoop.\nHP\u2019s new Big Data Reference Architecture for Hadoop offers an extremely flexible platform for the deployment of data lakes, whilst improving performance & efficiency. It meets the growing need for a scalable, modern architecture for the consolidation, storage, access, and processing of big data.\nHP Haven Big Data Software solutions can be used to augment Hadoop. HP\u2019s Vertica engine empowers fast analytics and includes a platform-agnostic SQL on Hadoop engine. The HP Autonomy IDOL engine makes sense out of unstructured data including text, voice, images and video, expanding the types of analytics you can perform with Hadoop, allowing you to build a smarter data lake.\nFinally, HP\u2019s Big Data Discovery Experience Services and HP Haven as a Service Solution for Hadoop provides you with an enterprise-class big data analytics Hadoop platform; which when coupled with our team of data scientists in Europe, can help you transition from science project to business value.\nSponsored by HP"}, "big-data-conference-uk-2015/public/schedule/detail/39741": {"room": "King's Suite - Sandringham", "title": "Spark Camp", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39741", "topics": "Tools & Technology", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/146540", "/big-data-conference-uk-2015/public/schedule/speaker/192647"], "timing": "9:00\u201317:00 Tuesday,  5/05/2015", "abstract": "Description\nSpark Camp, organized by the creators of the Apache Spark project at Databricks, will be a day-long, hands-on introduction to the Spark platform including Spark Core, the Spark Shell, Spark Streaming, Spark SQL, MLlib, and more. We will start with an overview of use cases and demonstrate writing simple Spark applications. We will cover each of the main components of the Spark stack via a series of technical talks targeted at developers who are new to Spark. Intermixed with the talks will be periods of hands-on lab work. Attendees will download and use Spark on their own laptops, and learn how to deploy Spark apps in distributed big data environments including common Hadoop distributions and Mesos.\nRelated\n\nSpark Developer Resources\n\n\nDeveloper Certification for Apache Spark now available online"}, "big-data-conference-uk-2015/public/schedule/detail/43651": {"room": "Westminster Suite", "title": "Practical machine learning - ask us anything", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43651", "topics": "Ask Us Anything", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/190800", "/big-data-conference-uk-2015/public/schedule/speaker/193739", "/big-data-conference-uk-2015/public/schedule/speaker/205568"], "timing": "16:15\u201316:55 Wednesday,  6/05/2015", "abstract": "Pragmatic approach to data science, data science pipeline, and machine learning for different vertical applications.\nHow to train existing staff to take on data science and engineering challenges.\nWhere are the unicorns? How to find and hire great data scientists. How to evaluate their skillset.\nHow to build and manage an innovative data science team that integrates tightly with all business functions and deliver business value.\nOutsourcing analytics; understanding how effectively you can use \u2018data science as a service\u2019 by utilising a ready-made data science team."}, "big-data-conference-uk-2015/public/schedule/detail/43719": {"room": "King's Suite", "title": "Keynote with Joanne Hannaford", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43719", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193595"], "timing": "9:45\u20139:55 Thursday,  7/05/2015", "abstract": "Joanne Hannaford, Partner, Goldman Sachs."}, "big-data-conference-uk-2015/public/schedule/detail/43711": {"room": "Offsite", "title": "Mobile App Test", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43711", "abstract": "Mobile App Test", "speaker_urls": [], "timing": "17:45\u201318:00 Thursday,  7/05/2015"}, "big-data-conference-uk-2015/public/schedule/detail/40350": {"room": "Buckingham Room - Palace Suite", "title": "Data-Driven Business Day", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40350", "topics": "Business & Industry", "speaker_urls": [], "timing": "9:00\u201317:00 Tuesday,  5/05/2015", "abstract": "For business strategists, marketers, product managers, and entrepreneurs, Data-Driven Business looks at how to use data to make better business decisions faster. Packed with case studies, panels, and eye-opening presentations, this fast-paced day focuses on how to solve today\u2019s thorniest business problems with Big Data. It\u2019s the missing MBA for a data-driven, always-on business world."}, "big-data-conference-uk-2015/public/schedule/detail/40352": {"room": "Blenheim Room - Palace Suite", "title": "Sex, drugs and data: Using web data to add \u00a33bn to the UK economy", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40352", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/146754"], "timing": "17:05\u201317:45 Thursday,  7/05/2015", "abstract": "From September 2014 all illegal transactions to which all parties consent will be included in UK national accounts. That includes prostitution. The UK\u2019s Office of National Statistics have done a good job at estimating the contribution that prostitution makes to the UK economy using a 10-year-old survey and some statistical assumptions.\nBut is it possible to do a better job at estimating the economic contribution of prostitution and rely on fewer assumptions?\nMany of the activities associated with prostitution are illegal in the UK, but paying for sex is actually legal and prostitution is therefore widely marketed on the web.\nUsing modern web data techniques and technologies, it is possible to count the number of people advertising sex for sale and for how much, and to use these real-time numbers to get a more accurate estimate of the economic activity in this area.\nIn this presentation Andrew Fogg will go into exactly how he was able to get all this data, why the missing-men matter (to the tune of \u00a33bn), and for the first time will share new data around pricing of prostitution.\nTime for another restatement of GDP?"}, "big-data-conference-uk-2015/public/schedule/detail/39695": {"room": "King's Suite", "title": "Hadoop and healthcare", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39695", "topics": "Keynotes, \r\n\t\t\r\n\t\t\tSponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/164706"], "timing": "9:45\u20139:50 Wednesday,  6/05/2015", "abstract": "Description\nWe are at a pivotal moment in the history of healthcare. Information is now available on almost everything that determines our health, which in turn can be translated into better, more effective and more efficient care. Our healthcare system should be a digital pioneer, using data to provide better outcomes for the taxpayer and patients through improved and streamlined care.\nThe huge amount of data currently stored by the NHS represents an enormous untapped resource, when considering how our healthcare system can be made more effective. By centralizing these records and mining the information, crucial insights will be found into how resources can be allocated as efficiently as possible, and where the gaps in healthcare provision are to be found.\nIt is in all of our interests to embrace big data; however, the benefits of such a project have not been fully communicated to the public. More needs to be done to mitigate the fears and concerns of those worried about the use of our data and explain the life-enhancing benefits of data-driven healthcare.\nOne hospital in California has utilized Hadoop technology to build predictive models and algorithms that monitor trends to intercept and avert infections, and monitor patient recovery for complications, drastically improving the level of care provided for patients. Doctors are informed immediately when patients\u2019 vitals cross a key threshold, enabling round-the-clock observation of large numbers of patients. The hospitals of the future are very much within reach, and here in the UK we should be leading the way.\nBig data can also be utilized to get to grips with the outbreak of an epidemic, enabling humanitarian agencies to determine where a disease is going to spread to next and therefore allocate resources in a target way to bring the outbreak under control. Real-time multi-center ingest collating unstructured data from a diverse array of sources offers unprecedented insights into how and where best to respond, and where precious resources would have the biggest impact.\nSponsored by WANdisco"}, "big-data-conference-uk-2015/public/schedule/detail/40059": {"room": "King's Suite - Sandringham", "title": "Leading change in data engineering", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40059", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/189922"], "timing": "17:05\u201317:45 Wednesday,  6/05/2015", "abstract": "Description\nCompare the Market\u2019s data architect Rob Siwicki and senior project manager Neil Martin will present the lessons learned whilst delivering a successful yet complex multifaceted project to reinvigorate the organisation\u2019s data infrastructure. In the process they will illustrate how Hadoop has played a pivotal role in being able to deliver right-time, high quality data products, and how the platform has initiated a step change in agility within the data engineering team.\nThe challenges of the legacy data infrastructure and the organisational context will be outlined, followed by the actions and techniques used to deliver the new IT enablers, engage stakeholders, and ultimately generate a positive and sustainable change in both technology and people in a fast-paced e-commerce environment. This is an environment where units of work are frenetically traded between teams written on post-it-notes, and exchanged and tracked on Kanban boards.\nSuch actions include:\n-\tThe development of a technology vision supporting key 7 strategic themes:\n-\tData definitions and governance\n-\tOperational analytics\n-\tTactical data delivery\n-\tNext generation infrastructure\n-\tData interfaces\n-\tCustomer relationship management\n-\tPersonalisation\n-\tThe creation of a guiding coalition of stakeholders\n-\tCommunicating the technology vision\n-\tEstablishing a sense of urgency\n-\tBuilding short-term quick wins and confidence with the help of the Cloudera team\n-\tEliminating obstacles to success\nThe advantages of Hadoop will be presented, with the outcomes of the current phase of the implementation and expected business benefits. The analysis of outcomes will be followed by a prediction of the new challenges the data team will face as the next two years unfold, and the continued implementation of the technical strategy unlocks greater potential for the use of Hadoop and CTM\u2019s data."}, "big-data-conference-uk-2015/public/schedule/detail/43549": {"room": "Windsor Suite", "title": "Oozie or easy: Managing Hadoop workflows the EASY way", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43549", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/202824"], "timing": "16:15\u201316:55 Wednesday,  6/05/2015", "abstract": "According to Gartner Inc., about 2/3 of all organizations are investing in big data and Hadoop but only 8% have production applications. Given the universal acceptance that big data is a huge competitive differentiator, it\u2019s likely that the companies that have not yet deployed big data applications are struggling to get their arms around this new technology. Industry experts agree that Hadoop and its ecosystem are extending the enterprise IT fabric rather than replacing any major portions of it. This is particularly evident with workflow management, where Hadoop jobs are growing in volume and complexity and are becoming more intertwined with many existing technologies. For IT organizations that already are overwhelmed by a proliferation of management tools, the ideal solution would be support for Hadoop\u2019s new workloads by the existing tools already in place; and more importantly, that already meet the required standards for governance, ease of use, reporting, planning, and service level management. Such an approach will allow IT to leverage existing staff and mature best practices rather than having to re-invent the wheel yet again specifically for Hadoop.\nThis session is sponsored by BMC Software"}, "big-data-conference-uk-2015/public/schedule/detail/39698": {"room": "King's Suite - Sandringham", "title": "Information architecture for Apache Hadoop", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39698", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/191200"], "timing": "11:45\u201312:25 Thursday,  7/05/2015", "abstract": "Description\nThe Hadoop ecosystem includes a range of tools which together make it possible to build an enterprise data hub capable of storing, processing, and analysing a wide variety of data. However, a platform with such broad capability triggers a question: how to organise the myriad data sets in a way that allows users to explore all the data, discover new data sets, and perform the necessary processing and analysis on the data they need?\nThis session will answer that question by outlining an information architecture for an enterprise data hub based on Hadoop. This is composed of a number of layers or zones that are designed to allow an organisation to:\n\nIngest data in its full fidelity, in as close to its original, raw form as possible\nProvide a data discovery and exploration facility for analysts and/or data scientists\nBring together and link multiple data sets to provide a business-wide data model\nCreate views of the data that are optimised for the access patterns generated by particular use cases\n\nThe session will describe the layers required in an information architecture that can provide these functions, with reference to the particular technologies within the Hadoop ecosystem that enable them."}, "big-data-conference-uk-2015/public/schedule/detail/43622": {"room": "King's Suite", "title": "Ideas that Matter", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43622", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/204542"], "timing": "10:05\u201310:25 Wednesday,  6/05/2015", "abstract": "We\u2019re always talking about \u201cinnovation\u201d, but \u2013 says Tim Harford \u2013 there are really two very different kinds of innovation. Using stories from sports, science, music, and military history, Tim will make you think different about where good ideas come from and how they should be encouraged."}, "big-data-conference-uk-2015/public/schedule/detail/43623": {"room": "King's Suite - Balmoral", "title": "Ideas that Matter", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43623", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/204542"], "timing": "10:55\u201311:35 Wednesday,  6/05/2015", "abstract": "We\u2019re always talking about \u201cinnovation\u201d, but \u2013 says Tim Harford \u2013 there are really two very different kinds of innovation. Using stories from sport, science, music and military history, Tim will make you think different about where good ideas come from and how they should be encouraged."}, "big-data-conference-uk-2015/public/schedule/detail/39865": {"room": "King's Suite - Balmoral", "title": "Big data 2.0 democratizes machine learning technology for Wall Street", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39865", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/150353"], "timing": "14:05\u201314:25 Thursday,  7/05/2015", "abstract": "Description\nThe promises and hype of big data over the last five years have largely gone unrealized. What was heralded as a panacea technology has been hamstrung by a lack of technical abilities. Meaning, massive scale systems costing millions have brought little value, as the manpower required to extract value from them has been in short supply. This has been exceedingly true on Wall Street, where hundreds of millions has been spent on big data tools and most analysis is still done manually. In essence, the big data 1.0 era, with its dependence on data scientists with rare skills, failed to give The Street competitive tools and failed to deliver on the hype.\nWith a new era of big data 2.0, automated, intelligent, machine learning systems are allowing Wall Street banks to finally take advantage of the massive value of the data they hold. They are finding solutions to problems and building predictive systems in weeks that previously required teams of experts and years to tackle.\nToo often big data 1.0 resulted in small, one-off insights. In contrast, automated predictive systems deliver repeatable and ongoing bottom-line ROI by actually making company employees better at their jobs on a day-to-day basis.\nFrom sales automation, to fraud detection, to insider threat monitoring, to automated hedge calculation, big data 2.0 is enabling increased transparency into global financial market conditions, including the global equities, FICC, and implied volatility markets."}, "big-data-conference-uk-2015/public/schedule/detail/39750": {"room": "King's Suite - Balmoral", "title": "Forecasting space-time events", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39750", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/150987"], "timing": "16:15\u201316:55 Wednesday,  6/05/2015", "abstract": "Description\nThis session uses the speaker\u2019s experience in building a crime forecasting package to outline some tools and techniques useful in modeling space-time event data. While the case study focuses on modeling crime, the techniques and tools presented are applicable to a broad selection of domains. In particular, attendees will leave the session with:\n\nAn understanding of key concepts in modeling space-time events\nAn introduction to the open source GeoTrellis framework for raster processing\nAn overview of the modeling pipeline used within the case study\n\nConcepts\nWhile many data scientists work with data that includes geographic information, this data is often used in rather rudimentary ways or limited to vector data sets such as the point locations of stores or users. The session will introduce the strengths and weaknesses behind raster-based geographic analysis.  Some challenges faced when modeling data at a fine geographic and temporal resolution will be discussed.   For example, how can uncertainty around the time of occurrence for events be represented?\nGeoTrellis\nThe case study leverages the open source GeoTrellis framework to conduct geographic processing.  GeoTrellis is currently an incubating project within the Eclipse Foundation\u2019s LocationTech working group.  The project provides fast and scalable geographic processing with an emphasis on raster-based analysis and routing through transportation networks.  Already written in Scala, GeoTrellis is currently being extended to integrate with Apache Spark.\nModeling\nThe modeling pipeline within the case study consists of several loosely coupled components.  In addition to GeoTrellis, the project uses R for machine learning and the Amazon Simple Workflow service for pipeline orchestration.  The presentation will outline the basic structure of the modeling process including details of the statistical techniques utilized within the process.\nSeveral statistical techniques were examined throughout the development of the project. The final approach included a stacked model incorporating a gradient boosting machine (GBM) to model the presence of events, and a generalized additive model (GAM) to transform these predictions into expected counts. The session will conclude by outlining some approaches to evaluating predictive accuracy for these types of data sets."}, "big-data-conference-uk-2015/public/schedule/detail/39860": {"room": "Buckingham Room - Palace Suite", "title": "SPARKTA: A real-time analytics platform based on Apache Spark", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39860", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193620", "/big-data-conference-uk-2015/public/schedule/speaker/205692"], "timing": "13:45\u201314:25 Thursday,  7/05/2015", "abstract": "Description\nNowadays, all kinds of businesses need to deal with real-time information in order to successfully deliver their core services. From social networks to security management, from real users to virtual processes, from high-level dashboards to IT monitoring\u2026 more and more sectors, consumers, and business processes require quick answers updated in real time.\nSome initiatives have tried to solve this problem, but until now most of them were complex or obsolete while others were not open source. For that reason Stratio created SPARKTA: an open source and full-featured platform for real-time analytics, based on Apache Spark.\nWith absolutely no coding, you can simultaneously deploy several user-defined aggregation workflows, where you can decide which rollups and dimensions will be applied to the event stream, in real-time. Each workflow has its own aggregation policy where you can select which input (Kafka, Flume, Twitter, etc.), output (MongoDB, Cassandra, etc.), event parser functions (decoding, enrichment, normalization), and aggregation functions (time-based, geo-range, hierarchical counting, sum, max, min, count, sumsquares, etc.) will be executed by SPARKTA.\nMoreover, the query services layer allows you to access the data easily, e.g., time-range queries with automatic selection of the best rollup, or ad-hoc aggregation for this subset of data.\nSPARKTA was also designed to be highly configurable and extensible, and since it is pure Spark, it will also benefit also from the entire Spark ecosystem.\nThanks to this technology, real-time analysis is readily available for every use case: SPARKTA is easy to deploy, but also fast, scalable, and fault-tolerant."}, "big-data-conference-uk-2015/public/schedule/detail/39900": {"room": "St. James / Regents", "title": "Multi-model databases and the art of aircraft maintenance", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39900", "topics": "IoT/Machine Data", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193589"], "timing": "11:45\u201312:25 Wednesday,  6/05/2015", "abstract": "Description\nWe describe a case study in aircraft fleet management, where we needed a database that would store data about all the different parts and subunits of an aircraft. A single aircraft already contains some 6,000,000 parts, not counting components.\nThe particular structure of the queries arising naturally from day-to-day processes quickly led to the insight that no single data model was sufficient to ensure satisfactory performance. Whichever data model we tried, there was always at least one important query that would either take ages to complete or be unbearably complicated, or indeed both.\nAfter a lot of frustration, the happy end could be achieved by using a multi-model database, which is a document store, a graph database, and a key/value store \u2013 all in one engine \u2013 held together by a common and flexible query language. Suddenly, all pieces fell into place and all required queries could be performed not only quickly, but also conveniently!\nIn this approach, parts and subunits are represented by JSON documents, which are the vertices of a graph, and the edges of the graph describe the containment. In this way, using graph queries, one can quickly find out, for example, what the smallest replaceable component containing a certain broken part is. As a further example, using document queries and secondary indexes, one can quickly find all documents corresponding to parts or subunits that need maintenance in the next week.\nIn this talk we tell the story of this case study, and explain why it was a real eye-opener that taught us a lesson about data modeling in general as well as database engines in particular, that will help us in a large class of other use cases."}, "big-data-conference-uk-2015/public/schedule/detail/39902": {"room": "Blenheim Room - Palace Suite", "title": "Using data science to transform OpenTable into your local dining expert", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39902", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193638"], "timing": "14:35\u201315:15 Thursday,  7/05/2015", "abstract": "Description\nI will talk about how we are using data science to help transform OpenTable into a local dining expert who knows you very well, and can help you and others find the best dining experience wherever you travel! This entails a whole slew of tools from natural language processing, recommendation system engineering, sentiment analysis, to predictions based on internal and external signals, that have to work in synch to make this magical experience happen. In the first part of the talk I will describe how we extract insights from our unstructured textual data using several NLP tools, such as topic modeling, n-grams analysis, and sentiment analysis. In the second part of the talk I will describe how we are combining those insights with restaurant and user metadata, as well as context, to generate meaningful recommendations. I will cover the stack of recommendation tools we use at OpenTable including matrix factorization, similarity and content-based models, and factorization machines."}, "big-data-conference-uk-2015/public/schedule/detail/39592": {"room": "King's Suite - Balmoral", "title": "Measuring the benefit effect for customers with Bayesian predictive modeling", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39592", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/145780"], "timing": "14:55\u201315:15 Wednesday,  6/05/2015", "abstract": "Description\nOffering benefits is a classic and important strategy for acquisition of new customers and churn management. This strategy consists of customer targeting and offering benefits, and its purposes include improving awareness and impressions of services/products, and attracting new customers.\nMethods for customer targeting procedures have been significantly improved by various statistical methods and algorithms. Unfortunately, the benefits offering step has suffered from a lack of effective methods due to insufficient customer data, a wide variety of benefits, and most of all, requiring predictions of customer reactions.\nRecently, several alternatives have been proposed such as A/B testing, which is easily applicable and modifiable. However, these methods have several issues such as lack of long-term prediction, mandatory modification of data/benefits, and limitation in quantitative comparison of testing options and the influence of external factors/treatment.\nIn this presentation, a new approach is proposed that integrates multivariate testing and a Bayesian time series prediction model to measure casual inference. This approach is implemented in R and Google\u2019s CausalImpact package. An empirical application of the approach is presented. A discussion will follow the conclusion."}, "big-data-conference-uk-2015/public/schedule/detail/42670": {"room": "King's Suite", "title": "Road to real-time digital business", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42670", "topics": "Keynotes, \r\n\t\t\r\n\t\t\tSponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/10028"], "timing": "9:15\u20139:25 Thursday,  7/05/2015", "abstract": "Big data and analytics continues to be a disruptive business force. Are we entering another phase \u2013 real-time digital business transformation, where businesses are realizing that the time to adjust to market and customer opportunities and threats is shrinking quickly? Leveraging historical and streaming data with \u201cjust-in-time\u201d analytics at the time of business decisions is on the horizon \u2013 and in the future machine learning will play an important role in automating many business actions and processes. All this is spurring huge innovation strides across the industry and open source communities.\nRod will focus on what businesses are looking for in the next few years and which technologies on the horizon will meet the challenge.\nSponsored by IBM"}, "big-data-conference-uk-2015/public/schedule/detail/39985": {"room": "King's Suite - Sandringham", "title": "The year in review - key changes in the Hadoop platform in the past 12 months", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39985", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/144901"], "timing": "16:15\u201316:55 Wednesday,  6/05/2015", "abstract": "Description\nEvolution wasn\u2019t supposed to work at this pace.\nWith hundreds of developers from a variety of organizations participating, Hadoop moves quickly. In the past 12 months, we\u2019ve seen major feature and functionality additions to the core platform as well as new elements entering and becoming standard parts of a Hadoop deployment.\nThis talk will survey the important changes admins and users should be aware of and their impacts on various use cases. We will cover all aspects of the Hadoop stack including:\n- Core storage \u2013 HDFS, HBase\n- Development frameworks like Spark, MapReduce\n- Resource Management on Hadoop with YARN, Llama, and other efforts\n- Ingest tools including Flume, Sqoop, Kafka\n- Data Processing frameworks such as Hive, Solr, Impala, and Pig\n- Access tools \u2013 Hue\nAt the end of this talk, you should be able to come away with a good grasp of how Hadoop has evolved recently and which features may be applicable to your environment."}, "big-data-conference-uk-2015/public/schedule/detail/39625": {"room": "King's Suite - Balmoral", "title": "Architectural considerations for Hadoop applications", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39625", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/126882", "/big-data-conference-uk-2015/public/schedule/speaker/147273", "/big-data-conference-uk-2015/public/schedule/speaker/169835", "/big-data-conference-uk-2015/public/schedule/speaker/134675"], "timing": "9:00\u201312:30 Tuesday,  5/05/2015", "abstract": "Description\nImplementing solutions with Apache Hadoop requires understanding not just Hadoop, but also a broad range of related projects in the Hadoop ecosystem such as Hive, Pig, Oozie, Sqoop, and Flume. The good news is that there\u2019s an abundance of materials \u2013 books, websites, conferences, etc. \u2013 for gaining a deep understanding of Hadoop and these related projects. The bad news is there\u2019s still a scarcity of information on how to integrate these components to implement complete solutions.\nIn this tutorial we\u2019ll walk through an end-to-end case study of a clickstream analytics engine to provide a concrete example of how to architect and implement a complete solution with Hadoop. We\u2019ll use this example to illustrate important topics such as:\n- Modeling data in Hadoop\n- Selecting optimal storage formats for data stored in Hadoop\n- Moving data between Hadoop and external data management systems such as relational databases\n- Moving event-based data such as logs and machine-generated data into Hadoop\n- Accessing and processing data in Hadoop\n- Orchestrating and scheduling workflows on Hadoop\nThroughout the example, best practices and considerations for architecting applications on Hadoop will be covered. This tutorial will be valuable for developers, architects, or project leads who are already knowledgeable about Hadoop and are now looking for more insight into how it can be leveraged to implement real-world applications."}, "big-data-conference-uk-2015/public/schedule/detail/39689": {"room": "Buckingham Room - Palace Suite", "title": "Systems that enable data agility: Lessons from LinkedIn", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39689", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/177568"], "timing": "13:45\u201314:25 Wednesday,  6/05/2015", "abstract": "Description\nCongratulations, you\u2019ve got a lot of data! Now what? How do you enable your organisation to create value from that data? What tools do your data scientists need in order to create data-driven products? How do you empower your teams to experiment, to innovate, and to be agile in response to customer needs?\nIn this session we will discuss LinkedIn\u2019s approach to solving these problems, and the open source tools that were created at LinkedIn to support data agility in a large organisation. The approach boils down to a few simple ideas:\n\nMake all data available centrally, in real time. If it\u2019s too difficult to access data across silos, you can\u2019t derive value from it. For this purpose, LinkedIn created Apache Kafka, which can be the data exchange backbone of your organisation.\nMake it easy to analyse and process that data. You\u2019ve hired smart people, now empower them to easily try out new ideas for data-driven products, and rapidly get them into production if they are good. To support this, LinkedIn created Apache Samza, a stream processing framework that provides powerful, reliable tools for working with data in Kafka.\n\nSince Kafka and Samza are open source, you can apply these lessons and start implementing your own agile data pipeline today. In this talk you\u2019ll learn about:\n\nHow Kafka and Samza reliably scale to millions of messages per second\nWhat kinds of real-time data problems you can solve with Samza\nHow Samza compares to other stream processing frameworks\nHow data streams support collaboration between different data science, product, and engineering teams within an organisation\nLessons learned on how to move fast without breaking things"}, "big-data-conference-uk-2015/public/schedule/detail/39932": {"room": "King's Suite - Sandringham", "title": "Adding insert, update, and delete to Hive", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39932", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/163846"], "timing": "16:15\u201316:55 Thursday,  7/05/2015", "abstract": "Description\nApache Hive provides a convenient SQL query engine and table abstraction for data stored in Hadoop. Hive uses Hadoop to provide highly scalable bandwidth to the data, but until recently did not support updates, deletes, or transaction isolation. This has prevented many desirable use cases such as updating of dimension tables or doing data cleanup. We have implemented the standard SQL commands insert, update, and delete allowing users to insert new records as they become available, update changing dimension tables, repair incorrect data, and remove individual records. This also allows very low latency ingestion of streaming data from tools like Storm and Flume. Additionally, we have added ACID-compliant snapshot isolation between queries so that queries will see a consistent view of the committed transactions when they are launched. This talk will cover the intended use cases, architectural challenges of implementing updates and deletes in a write-once file system, performance of the solution, and details of changes to the file storage formats and transaction management system."}, "big-data-conference-uk-2015/public/schedule/detail/39725": {"room": "Buckingham Room - Palace Suite", "title": "Spark on Mesos", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39725", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/77526"], "timing": "14:35\u201315:15 Thursday,  7/05/2015", "abstract": "Description\nSpark is an open-source computation platform for big data that supports both batch-mode (\u201coffline\u201d) data analysis, just like MapReduce, but also processing of event streams, embedded SQL queries, and other extensions.\nWhile Spark is most often discussed as a replacement for MapReduce in Hadoop clusters, Spark is actually agnostic to the underlying infrastructure for clustering, so alternative deployments are possible.\nMesos offers resource management and scheduling services comparable to YARN, making it a viable alternative. The advantages of Mesos include greater flexibility for non-Hadoop, clustered applications and more fine-grained resource management. The disadvantages of Mesos include the ecosystem of other tools that require Hadoop, which you might need to use.\nWe\u2019ll use several example applications to discuss pragmatic details for Spark on Mesos, including streaming, batch-mode, and interactive application deployment tuning, and integration with databases and distributed file systems. We\u2019ll contrast Mesos vs. YARN performance characteristics. Finally, we\u2019ll make recommendations on when to use Spark on Mesos, when to stick with Hadoop, and how to be successful in either case."}, "big-data-conference-uk-2015/public/schedule/detail/42528": {"room": "King's Suite", "title": "Bringing life to design: Data science in 3D", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42528", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/4213"], "timing": "9:25\u20139:35 Thursday,  7/05/2015", "abstract": "Jet engines, lifelike movie monsters, cancer-fighting nanorobots, and bespoke products.\nWe live in a world where everything around us is designed by someone.  The pace of innovation is escalating and with new methods of manufacturing, such as 3D printing, the demands placed on designers and design technology are increasing.\nWhat if there was a better way to organize all this information and allow ideas and creations to emerge more organically? We will explore how the design software of the future can emulate nature through the application of data science to 3D data. We introduce a geometric shape analysis and machine learning technology we call the Design Graph. By learning from millions of 3D models and then assembling a knowledge graph, it is able to react to a constantly-evolving world, guiding the designs of the future."}, "big-data-conference-uk-2015/public/schedule/detail/39870": {"room": "St. James / Regents", "title": "Smart cars of tomorrow: real-time driving patterns", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39870", "topics": "IoT/Machine Data", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193625", "/big-data-conference-uk-2015/public/schedule/speaker/171147", "/big-data-conference-uk-2015/public/schedule/speaker/184253"], "timing": "17:05\u201317:45 Wednesday,  6/05/2015", "abstract": "Description\nIn recent years, the adoption of electric cars has resulted in a desperate need from carmakers for accurate range prediction. In addition, fuel efficiency is of increasing concern due to today\u2019s ever-rising fuel costs. In this talk, we will outline a machine learning framework for real-time data analysis to demonstrate how live data collected from cars can be used to provide valuable information for range prediction and smart navigation.\nFor our solution, we use a Bluetooth dongle that connects to a standard OBD II car diagnostics data port. Together with a self-developed iOS app we can then stream OBD II data into our framework\u2019s big data infrastructure for long-term storage, batch training processes, and subsequent real-time analysis. We will show how we used different open-source technologies (Spring XD, Python, and others) to stream, store, and reason over this data in a scalable way.\nIn particular, we will focus on how we designed the machine learning framework to derive individual driver \u2018fingerprints\u2019 from variables such as speed, acceleration, driving times, and location, taken from historical data. These fingerprints are then used within the real-time prediction framework to determine final journey destination and driving behavior in real time during the journey. We will also look at how other public and free data sources such as traffic information, weather, and fuel station locations could be used to further improve the accuracy and scope of our models.\nThis talk is intended to demonstrate pioneering work in the space of big data and the connected car. We will take into consideration the insights we have gained from building this prototype, both into infrastructure and analysis, to give our view on what such real-time driving intelligence applications of tomorrow could look like."}, "big-data-conference-uk-2015/public/schedule/detail/42720": {"room": "Windsor Suite", "title": "The age of agile analytics has arrived!", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42720", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/146171"], "timing": "10:55\u201311:35 Thursday,  7/05/2015", "abstract": "Most organizations nowadays see the massive value potential in (big) data analytics. What most of them still fear is that starting an analytics initiative will result in a massive IT project that will take 12-18 months before first analytical results are achieved \u2013 and deploying the results to generate business value will take another 12-18 months.\nEnter agile analytics: agile analytics is a rapid approach to experimenting in analytical projects. Model building and advanced analytics is in principle an iterative process. The agile analytics framework focuses on reducing this iteration time so that analysts can provide organizations with better answers more quickly.\nIn this presentation we will describe a general framework for agile analytics. It involves teams of business users and analysts, requires a fail fast/agile mindset, and drives direct benefits to the business.\nWe will show a use case done in a big data lab environment. In that case first pre-production results from raw data to a powerful predictive model were generated within four weeks.\nSponsored by Teradata"}, "big-data-conference-uk-2015/public/schedule/detail/40529": {"room": "Hilton Meeting Room 4-6", "title": "Cloudera essentials for Apache Hadoop", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40529", "topics": "Training", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/145657"], "timing": "9:00\u201317:00 Tuesday,  5/05/2015", "abstract": "Cloudera University\u2019s one-day essentials course presents an overview of Apache Hadoop and how it can help decision-makers meet business goals, providing a fundamental introduction to the main components of Hadoop and its use cases in various industries. This course is a good starting point for any role or set of objectives and is part of the data analyst learning path.\nHands-On Hadoop\nThrough instructor-led discussion and interactive, hands-on exercises, participants will navigate the Hadoop ecosystem, learning topics such as:\n\nThe occasions in which Hadoop is the appropriate platform for managing and analyzing data\nThe ways organizations in different verticals use Hadoop to maximize the value of data\nHow Hadoop fits into the existing hardware, software, and data environment\nWhat you need to know about choosing Hadoop for your company\nWhich resources are necessary to effectively deploy Hadoop in development and production\n\nTraining Overview\nAudience & Prerequisites\nThis course is best suited to anyone who wants the big picture of Hadoop in the enterprise: CTOs, CIOs, technical managers, architects, data analysts, developers, administrators. A basic level of technical proficiency is valuable. Prior knowledge of Apache Hadoop is not required."}, "big-data-conference-uk-2015/public/schedule/detail/43221": {"room": "Westminster Suite", "title": "Hadoop Application Architectures - ask us anything", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43221", "topics": "Ask Us Anything", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/147273", "/big-data-conference-uk-2015/public/schedule/speaker/134675", "/big-data-conference-uk-2015/public/schedule/speaker/126882", "/big-data-conference-uk-2015/public/schedule/speaker/169835"], "timing": "14:35\u201315:15 Wednesday,  6/05/2015", "abstract": "Join the authors of Hadoop Application Architectures for an open Q/A session on considerations and recommendations for architecture and design of applications using Hadoop. Talk to us about your use-case and its big data architecture, or just come to listen in."}, "big-data-conference-uk-2015/public/schedule/detail/42725": {"room": "Windsor Suite", "title": "Lowering the entry point to getting going with Hadoop and obtaining business value", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42725", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/192158"], "timing": "11:45\u201312:25 Wednesday,  6/05/2015", "abstract": "Today there is a perfect storm. Organizations are interested in the promises of Hadoop, but are struggling with the exploding ecosystem and a shortage of skills to navigate and benefit from it. The end result is that many organizations are limiting their ambitions when it comes to exploiting Hadoop. Just like you, SAS is convinced that Hadoop is the basis for the next generation of BI and analytics. This presentation shares how SAS can help spread the use of Hadoop to less technical audiences, showcasing some of the end-user technologies already implemented at SAS customers that can help across the spectrum of data ingestion and management, visualization, and analytics.\nSponsored by SAS"}, "big-data-conference-uk-2015/public/schedule/detail/41054": {"room": "King's Suite", "title": "Thursday Keynote Welcome", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/41054", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/5107", "/big-data-conference-uk-2015/public/schedule/speaker/103766", "/big-data-conference-uk-2015/public/schedule/speaker/17816"], "timing": "9:00\u20139:05 Thursday,  7/05/2015", "abstract": "Program Chairs Roger Magoulas, Doug Cutting, and Alistair Croll welcome you to the second day of keynotes."}, "big-data-conference-uk-2015/public/schedule/detail/39919": {"room": "St. James / Regents", "title": "How to talk to a house", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39919", "topics": "IoT/Machine Data", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/163199"], "timing": "14:35\u201315:15 Wednesday,  6/05/2015", "abstract": "Description\nMachine learning and Internet of Things are a natural combination. The growth of data and devices needs both new ways of thinking about data, and about programming.\nThis session introduces some ideas about a new model of programming through self-contained micro services orchestrated by machine learning algorithms. It is about programming through training probabilistic models instead of deterministic control systems.\nThe technology stack will demonstrate Kafka, Spark, and R among others.\nThe project is a personal one in a relatable domain. I will share a few things learnt from taking programming from the purely digital world into something with physical consequences, and how messing with the lights leads to programming in the dark."}, "big-data-conference-uk-2015/public/schedule/detail/41053": {"room": "King's Suite", "title": "Wednesday Keynote Welcome", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/41053", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/5107", "/big-data-conference-uk-2015/public/schedule/speaker/103766", "/big-data-conference-uk-2015/public/schedule/speaker/17816"], "timing": "9:00\u20139:10 Wednesday,  6/05/2015", "abstract": "Program Chairs Roger Magoulas, Doug Cutting, and Alistair Croll welcome you to the first day of keynotes."}, "big-data-conference-uk-2015/public/schedule/detail/42408": {"room": "Monarch Suite", "title": "Attendee Reception", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42408", "topics": "Events", "speaker_urls": [], "timing": "17:45\u201318:45 Wednesday,  6/05/2015", "abstract": "Join us at the Attendee Reception for a drink or two. Network with other attendees while visiting our companies innovating in the data space. This event is open to all sponsors, exhibitors, and attendees."}, "big-data-conference-uk-2015/public/schedule/detail/39913": {"room": "King's Suite - Sandringham", "title": "Transparent encryption in HDFS", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39913", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/185467", "/big-data-conference-uk-2015/public/schedule/speaker/157428"], "timing": "14:35\u201315:15 Thursday,  7/05/2015", "abstract": "Description\nData encryption is a requirement for many business sectors dealing with confidential information, such as finance, healthcare, and government. For example, HIPAA, FISMA, and DCI all require that data is encrypted while it is in-flight (being transferred over the network) and when it is at-rest (stored durably on disk). There can also be additional restrictions surrounding access, management, and storage of encryption keys.\nTo meet these requirements, transparent, end-to-end encryption was added to HDFS. Once configured, data read from and written to certain HDFS directories is transparently encrypted and decrypted without requiring any changes to user application code. This encryption is also end-to-end, meaning that data is protected both in-flight and at-rest, and can only be encrypted and decrypted by the client. This improves security since HDFS itself never handles unencrypted data or data encryption keys. Furthermore, through the use of a new cluster service, the Hadoop Key Management Server (KMS), the responsibilities of key administration and HDFS administration can be separated, further enhancing security.\nDuring this talk, we will cover the design, implementation, and usage of transparent encryption in HDFS. We will also cover performance results demonstrating the benefits of hardware crypto acceleration (AES-NI)."}, "big-data-conference-uk-2015/public/schedule/detail/39912": {"room": "St. James / Regents", "title": "Sharing humanitarian data at the United Nations", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39912", "topics": "Privacy, Law, & Ethics", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/126525"], "timing": "13:45\u201314:25 Thursday,  7/05/2015", "abstract": "Description\nOCHA (the UN\u2019s Humanitarian Affairs body) allocates international funding when there is an emergency or natural disaster. This can include anything from the Syrian refugee crisis and the Haiti earthquake to the Ebola virus. This work is fundamentally about data\u2014using information about refugee movements, the weather, and NGO capabilities to decide who can best use money to save the most lives.\nOCHA has hundreds of country offices, and also works with many partners, such as the Red Cross. All these gather lots of data during a crisis. They tend to store it in spreadsheets on their own systems, or share it with the world in PDF reports. In the necessary rush of emergency work, it\u2019s hard to find more time to put into data sharing.\nThe Humanitarian Data Exchange is a new project with a goal of increasing the reuse of data in the Humanitarian world. UN OCHA is building a data hub. It\u2019s based on the Open Knowledge Foundation\u2019s CKAN product. ScraperWiki is supporting the data collection process and providing technical project management.\nThe presentation will answer these questions:\n- What motivates people to share data? \n- What barriers must be overcome in data sharing during a crisis?\n- What features in a data hub do on-ground workers need?\n- How can a non-profit make best use of crowd sourcing from its volunteers?\n- What metrics best measure how useful a data hub is?\nLessons from the front line of humanitarian aid are invaluable in industry too. Every business is saying today: \u201cIt needs to be easier for our staff to share data with each other.\""}, "big-data-conference-uk-2015/public/schedule/detail/39601": {"room": "Blenheim Room - Palace Suite", "title": "Automating decision-making with big data: How to make it work", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39601", "topics": "Business & Industry", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/6649"], "timing": "16:15\u201316:55 Wednesday,  6/05/2015", "abstract": "Description\nConventional wisdom maps a progression from descriptive analytics (what has happened), via predictive analytics (what will happen), to prescriptive analytics (what should we do).\nThis development mirrors the increasing creation and availability of data, through the waves of computerized and networked business computing. It follows the money (CRM and ERP) to business software dealing with behavioral data (digital marketing software and HR software), to the next wave of autonomous devices, connected sensors, and the Internet of Things.\nDespite the amount of data that must be processed, which is growing by multiple orders of magnitude from wave to wave, the success of approaches in democratizing data access and visualization has been timid. If our strategy in dealing with big data is concluded in giving everyone access to visualizations, and simplifying visualizations so much that they can be consumed by everybody, we are going to fail.\nWe present an example of leading European companies that realize this problem and have unlocked the potential of big data in an entirely different way. They have automated their most critical, most decision-heavy, and most impactful business processes, including pricing, replenishment, or staffing, based on data that is extracted, processed, or turned into predictions. These predictions are turned into decisions that are put into action in minimal roundtrip time. We call these businesses predictive enterprises.\nIs there an analyst in this process? Only to provide oversight and make sure the machine is running smoothly? Are there data scientists in this process? Plenty.\nUnderstanding the core business, modeling the data and the decisions to prepare, are some of the most challenging tasks for data scientists in the world. With each small decision being automated, an aggregate of more intelligent, data-driven decisions leads to tremendous impact on the operational efficiency of the business.\nFor companies bent on following this example to become predictive enterprises, a set of tough challenges must be addressed:\n- Cultural challenges: How can we trust our core business to a black-box algorithm? What if something goes wrong? How do you reflect the biases of our team in the model?\n- Technical challenges: How to get access to the data in the first place \u2013 and how to execute decisions? How can we turn data scientists from system explorers into system builders, crafting fine-tuned automation processes?\n- Scientific challenges: How can we communicate decision quality, objectively and understandably? How can we keep models learning, accurate, and flexible at the same time?\nThis presentation is based on our experience in running a data science practice, and operating a customer\u2019s predictive applications on our predictive application platform as a service. In the final section of the presentation we will show what a predictive application platform as a service looks like, and how applications are built and operated."}, "big-data-conference-uk-2015/public/schedule/detail/40031": {"room": "King's Suite - Balmoral", "title": "Poor man's parallel pipelines", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40031", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/164744"], "timing": "14:35\u201314:55 Thursday,  7/05/2015", "abstract": "Description\nHadoop, Storm, and Spark are fantastic frameworks for processing massive amounts of data in parallel. Every now and then, there is a one-off data science task that could really use some speeding up. For those kind of tasks, it\u2019s probably not worthwhile to set up large frameworks. This presentation demonstrates GNU Parallel, which allows you to easily parallelize and distribute such tasks.\nGNU Parallel is a small command-line tool that requires no setup. It allows you to parallelize your task to multiple cores and even distribute it to multiple remote instances. This presentation zooms in on Chapter 8 of Data Science at the Command Line written by Jeroen Janssens and recently published by O\u2019Reilly.\nWe\u2019ll make use of Amazon Web Services to spin up remote instances during the presentation, although any cloud service and your own laptop can be used. No special setup is required. Topics that we\u2019ll cover during the presentation include:\n\nInstalling GNU Parallel\nProcessing many large files\nProcessing streaming data\nDiscovering remote instances\nKeeping a log of all the jobs\nTiming out, resuming, retrying, and monitoring jobs\n\nThrough real-world examples, we\u2019ll demonstrate how easy and effective GNU Parallel can be. For example, we\u2019ll use GNU Parallel to speed up downloading data from a web API using multiple connections, and how many machine learning models can be trained in parallel with different parameters. By the end of this presentation, you\u2019ll be able to set up and use GNU Parallel the next time you encounter a one-off data science task that could really use some speeding up."}, "big-data-conference-uk-2015/public/schedule/detail/39851": {"room": "Buckingham Room - Palace Suite", "title": "Using the Zeta Architecture: To become a hero", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39851", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/144388"], "timing": "14:35\u201315:15 Wednesday,  6/05/2015", "abstract": "Description\nIn this session, I\u2019ll explain how to move your business to the next level by implementing your enterprise architecture. I\u2019ll lay out which products can fit into this architecture in order to fulfill the needs of your business, as well as the benefits that can be derived from these components, both independently and together. With this architecture, log shipping is a thing of the past. It will no longer be needed, because this architectural simplification removes work that is required for most businesses to function and drive revenue. Log shipping is one less thing that employees will have to worry about in the wee hours of the night, and it won\u2019t break.\nBy storing the data where it is created in a distributed file system, and processing it in place, you can remove all the required transport technologies and simplify the application architectures of many enterprise applications, because the enterprise architecture solves these problems."}, "big-data-conference-uk-2015/public/schedule/detail/43941": {"room": "Windsor Suite", "title": "How being an information generation is driving Big Data and business change", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43941", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/206097"], "timing": "17:05\u201317:45 Wednesday,  6/05/2015", "abstract": "A brief walk through some of the developments that are happening now with Big Data at the core. Big Data and Analytics can truly be used to help anyone succeed at anything, but not without overcoming challenges.\nSponsored by EMC"}, "big-data-conference-uk-2015/public/schedule/detail/43687": {"room": "King's Suite", "title": "The data adventure in Santander", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43687", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193046"], "timing": "9:10\u20139:25 Wednesday,  6/05/2015", "abstract": "Maite Agujetas, CTO, Grupo Santander, Santander Group"}, "big-data-conference-uk-2015/public/schedule/detail/40535": {"room": "Hilton Meeting Room 4-6", "title": "Practical Machine Learning (Day 2)", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40535", "topics": "Training", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/190800"], "timing": "9:00\u201317:00 Thursday,  7/05/2015", "abstract": "This intensive two-day course will provide you with a condensed introduction to the key concepts and techniques of machine learning. It will allow you to know what is and is not possible with these exciting new tools, and understand how they can benefit your organization. It will give you the language and framework to talk to both experts and executives.\nThe course has a strong focus on gaining practical hands-\u00adon experience implementing sophisticated algorithms and building predictive models on real datasets. Importantly, you will also learn to evaluate the validity of the model and identify spurious findings. By the end of the two days, you will be ready to implement the algorithms on your own data, and immediately\ngenerate value. Finally, you will get a taste of the cutting edge techniques used at the likes of Google, Facebook, and Amazon, and guidance on how to further develop your skills.\nLearning Objectives\nIn this course, you will:\n\nGain a broad understanding of the machine learning universe, what is and is not possible with the latest techniques\nUnderstand the key elements of the machine learning toolkit\nWork through the components of a machine learning workflow (data to model to parameters to optimisation to predictions)\nLearn how to formulate your data into a machine learning problem, and choose the most appropriate technique to solve the problem\nExperience how machine learning tools provide insight and predictions, and allow personalisation\nDiscover how to understand, interpret, and convey the results of machine learning\nGain the ability to apply machine learning in novel situations\nHave familiarity with cutting edge techniques, and some perspective on the direction of the field"}, "big-data-conference-uk-2015/public/schedule/detail/40534": {"room": "Hilton Meeting Room 4-6", "title": "Practical machine learning (Day 1)", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40534", "topics": "Training", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/190800"], "timing": "9:00\u201317:00 Wednesday,  6/05/2015", "abstract": "This intensive two day course will provide you with a condensed introduction to the key concepts and techniques of machine learning. It will allow you to know what is and is not possible with these exciting new tools, and understand how they can benefit your organization. It will give you the language and framework to talk to both experts and executives.\nThe course has a strong focus on gaining practical hands-\u00adon experience implementing sophisticated algorithms and building predictive models on real datasets. Importantly, you will also learn to evaluate the validity of the model and identify spurious findings. By the end of the two days, you will be ready to implement the algorithms on your own data, and immediately\ngenerate value. Finally, you will get a taste of the cutting edge techniques used at the likes of Google, Facebook, and Amazon, and guidance on how to further develop your skills.\nLearning Objectives\nIn this course, you will:\n\nGain a broad understanding of the machine learning universe,\u00ad what is and is not possible with the latest techniques\nUnderstand the key elements of the machine learning toolkit\nWork through the components of a machine learning workflow (data to model to parameters to optimisation to predictions)\nLearn how to formulate your data into a machine learning problem, and choose the most appropriate technique to solve the problem\nExperience how machine learning tools provide insight and predictions, and allow personalisation\nDiscover how to understand, interpret, and convey the results of machine learning\nGain the ability to apply machine learning in novel situations\nHave familiarity with cutting edge techniques, and some perspective on the direction of the field"}, "big-data-conference-uk-2015/public/schedule/detail/40531": {"room": "Hilton Meeting Room 1-3", "title": "Apache Spark advanced training (Day 1)", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40531", "topics": "Training", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/189209", "/big-data-conference-uk-2015/public/schedule/speaker/108081"], "timing": "9:00\u201317:00 Tuesday,  5/05/2015", "abstract": "This three-day curriculum features advanced lectures and hands-on technical exercises for advanced Spark usage in data exploration, analysis, and building big data applications. Course materials emphasize architectural design patterns and best practices for leveraging Spark in the context of other popular, complementary frameworks for building and managing enterprise data workflows. Those who attend the training will have opportunities during the tutorial to meet and have discussions with key members of the Spark development community, including Q&A sessions and white-boarding for specific questions about use cases. Participants will also receive limited free-tier accounts on Databricks Cloud."}, "big-data-conference-uk-2015/public/schedule/detail/40533": {"room": "Hilton Meeting Room 1-3", "title": "Apache Spark advanced training (Day 3)", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40533", "topics": "Training", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/189209", "/big-data-conference-uk-2015/public/schedule/speaker/108081"], "timing": "9:00\u201317:00 Thursday,  7/05/2015", "abstract": "This three-day curriculum features advanced lectures and hands-on technical exercises for advanced Spark usage in data exploration, analysis, and building big data applications. Course materials emphasize architectural design patterns and best practices for leveraging Spark in the context of other popular, complementary frameworks for building and managing enterprise data workflows. Those who attend the training will have opportunities during the tutorial to meet and have discussions with key members of the Spark development community, including Q&A sessions and white-boarding for specific questions about use cases. Participants will also receive limited free-tier accounts on Databricks Cloud."}, "big-data-conference-uk-2015/public/schedule/detail/40532": {"room": "Hilton Meeting Room 1-3", "title": "Apache Spark advanced training (Day 2)", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40532", "topics": "Training", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/189209", "/big-data-conference-uk-2015/public/schedule/speaker/108081"], "timing": "9:00\u201317:00 Wednesday,  6/05/2015", "abstract": "This three-day curriculum features advanced lectures and hands-on technical exercises for advanced Spark usage in data exploration, analysis, and building big data applications. Course materials emphasize architectural design patterns and best practices for leveraging Spark in the context of other popular, complementary frameworks for building and managing enterprise data workflows. Those who attend the training will have opportunities during the tutorial to meet and have discussions with key members of the Spark development community, including Q&A sessions and white-boarding for specific questions about use cases. Participants will also receive limited free-tier accounts on Databricks Cloud."}, "big-data-conference-uk-2015/public/schedule/detail/43720": {"room": "Windsor Suite", "title": "Road to real-time digital business", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43720", "topics": "Sponsored", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/10028"], "timing": "11:45\u201312:25 Thursday,  7/05/2015", "abstract": "Big data and analytics continues to be a disruptive business force. Are we entering another phase \u2013 real-time digital business transformation, where businesses are realizing that the time to adjust to market and customer opportunities and threats is shrinking quickly? Leveraging historical and streaming data with \u201cjust-in-time\u201d analytics at the time of business decisions is on the horizon \u2013 and in the future machine learning will play an important role in automating many business actions and processes. All this is spurring huge innovation strides across the industry and open source communities.\nRod will focus on what businesses are looking for in the next few years and which technologies on the horizon will meet the challenge.\nSponsored by IBM"}, "big-data-conference-uk-2015/public/schedule/detail/40029": {"room": "King's Suite - Sandringham", "title": "Apache Kylin - Extreme OLAP engine for Hadoop", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40029", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193675", "/big-data-conference-uk-2015/public/schedule/speaker/193728"], "timing": "13:45\u201314:25 Wednesday,  6/05/2015", "abstract": "Description\nApache Kylin is an open source distributed analytics engine contributed by eBay Inc. that provides SQL interface and multi-dimensional analysis (OLAP) on Hadoop, supporting extremely large datasets. Kylin\u2019s pre-built MOLAP cubes, distributed architecture, and high concurrency helps users analyze multidimensional queries using  Kylin\u2019s SQL interface as well as via other BI tools like Tableau and MicroStrategy. Kylin is successfully deployed and used in eBay for a variety of production use cases, including web traffic analysis and geographical expansion analysis. It was open sourced on Oct 1, 2014 and has 320 stars and 125 forks.\nKylin was accepted as an Apache Incubator Project on Nov 25, 2014.\nBackground\nThe challenge faced at eBay is that our data volume has become bigger while our user base has become more diverse. Our users\u2014for example, in analytics and business units\u2014consistently ask for minimal latency but want to continue using their favorite tools, such as Tableau and Excel. We worked closely with our internal analytics community and outlined requirements for a successful product at eBay:\n- Sub-second query latency on billions of rows\n- ANSI SQL availability for those using SQL-compatible tools\n- Full OLAP capability to offer advanced functionality\n- Support for high cardinality and very large dimensions\n- High concurrency for thousands of users\n- Distributed and scale-out architecture for analysis in the TB to PB size range.\nWe quickly realized nothing met our exact requirements externally\u2014especially in the open-source Hadoop community. To meet our emergent business needs, we decided to build a platform from scratch. With an excellent team and several pilot customers, we have been able to bring the Kylin platform into production as well as open-source it.\nFeature highlights\nKylin is a platform offering the following features for big data analytics:\n- Extremely fast OLAP engine at scale \u2013 Kylin is designed to reduce query latency on Hadoop for 10+ billion rows of data.\n- ANSI SQL on Hadoop \u2013 Kylin supports most ANSI SQL query functions in its ANSI SQL on Hadoop interface.\n- Interactive query capability \u2013 Users can interact with Hadoop data via Kylin at sub-second latency\u2014better than Hive queries for the same dataset.\n- MOLAP cube query serving on billions of rows \u2013 Users can define a data model and pre-build in Kylin with more than 10+ billion raw data records.\n- Seamless integration with BI Tools \u2013 Kylin currently offers integration with business intelligence tools such as Tableau and third-party applications.\n- Open-source ODBC driver \u2013 Kylin\u2019s ODBC driver is built from scratch and works very well with Tableau. We have open-sourced the driver to the community as well.\nOther highlights\n- Job management and monitoring\n- Compression and encoding to reduce storage\n- Incremental refresh of cubes\n- Leveraging of the HBase coprocessor for query latency\n- Approximate query capability for distinct counts (HyperLogLog)\n- Easy-to-use web interface to manage, build, monitor, and query cubes\n- Security capability to set ACL at the cube/project level\n- Support for LDAP integration.\nAgenda\n- What\u2019s Kylin\n- Tech highlights\n- Performance\n- Open source\n- Q & A"}, "big-data-conference-uk-2015/public/schedule/detail/39844": {"room": "St. James / Regents", "title": "Being a good data citizen", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39844", "topics": "Privacy, Law, & Ethics", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/157263"], "timing": "16:15\u201316:55 Thursday,  7/05/2015", "abstract": "Description\nWe will start with a question, a simple guessing game that helps to explain how data can help everyone, everywhere, but how this is blocked by data being too hard.\nPart one: Data is hard\nThis section uses real world examples to call out old thinking and bad data behavior. It shows clearly the things we all do and think that make data hard. We will see real examples of bad data behavior everywhere, from your local coffee shop to the spreadsheet you just sent to your colleague.\nPart two: Making data easy\nThis section covers new thinking, a new approach to tools and how to be a good data citizen. It covers how to fit data into the wider context of real world organizations, a proposed new frame for thinking about how we should expect data to behave, and how to help make data easier by being a good data citizen."}, "big-data-conference-uk-2015/public/schedule/detail/40025": {"room": "King's Suite - Balmoral", "title": "Deep learning made doubly easy with reusable deep features", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40025", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/157232"], "timing": "17:05\u201317:45 Wednesday,  6/05/2015", "abstract": "Description\nDeep Learning is making news across the country as one of the most promising techniques in machine learning research. Every industry research lab is dedicating resources to unlock the deep learning potential in tasks such as image tagging, object recognition, speech recognition, and text analysis. Multiple open source packages are currently under development to provide tools for advanced practitioners. Much of the success, however, is locked away in black-box \u201ctuning\u201d methods and ornate network architectures. Furthermore, the process of training a deep learning network can be slow and finicky, and requires a tremendous amount of data to obtain accurate results. There are a lot of hoops to jump through before one can arrive at the magical land of deep learning goodness.\nIn this talk, we give a beginner-friendly explanation of deep learning using neural networks\u2014what it is, what it does, and how. To remove the barrier introduced by designing, training, and tuning networks, we demonstrate building deep learning classifiers tailored to your specific task using pre-trained models, which we call deep features. These features can be trained on one data set for one task and used to obtain good predictions on a different task, on a different data set.\nThis talk provides practical tips about deep learning. These ideas will be demonstrated using GraphLab Create, though the methodology is generally applicable. No prior experience is necessary."}, "big-data-conference-uk-2015/public/schedule/detail/39842": {"room": "Buckingham Room - Palace Suite", "title": "Big JSON, baffling performance", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39842", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/152293"], "timing": "17:05\u201317:45 Wednesday,  6/05/2015", "abstract": "Description\nThis will be a deep technical talk on Apache Drill\u2019s key architectural advantages and how they enable JSON analytics without setup at very high performance. We\u2019ll go into depth on the following:\n\nUse of runtime and compile code generation to provide adaptive execution\nUsing bytecode reengineering to improve performance and memory footprint\nThe nature of record batches, Drill\u2019s unit of work, and how it plays into both in-memory and on-wire performance\nThe performance advantage of columnar functions\nHow enhancements to self-describing schemas and the decentralization of metadata can change your data organization."}, "big-data-conference-uk-2015/public/schedule/detail/42743": {"room": "King's Suite", "title": "Is Privacy Becoming a Luxury Good?", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/42743", "topics": "Keynotes", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/181479"], "timing": "10:05\u201310:20 Thursday,  7/05/2015", "abstract": "We are being watched \u2013 by companies, by the government, by our neighbors. Technology has made powerful surveillance tools available to everyone. And now some of us are investing in counter-surveillance techniques and tactics. Julia Angwin discusses how much she has spent trying to protect her privacy, and raises the question of whether we want to live in a society where only the rich can buy their way out of ubiquitous surveillance."}, "big-data-conference-uk-2015/public/schedule/detail/43750": {"room": "Westminster Suite", "title": "Spark ask us anything", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/43750", "topics": "Ask Us Anything", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/146540", "/big-data-conference-uk-2015/public/schedule/speaker/152591"], "timing": "14:35\u201315:15 Thursday,  7/05/2015", "abstract": "Join the Spark team for an informal question and answer session. Spark committers from Databricks will be on hand to field a wide range of detailed questions. Even if you don\u2019t have a specific question, join in to hear what others are asking."}, "big-data-conference-uk-2015/public/schedule/detail/39702": {"room": "Blenheim Room - Palace Suite", "title": "Getting started with Apache Cassandra", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39702", "topics": "Tools & Technology", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/193514"], "timing": "9:00\u201312:30 Tuesday,  5/05/2015", "abstract": "Description\nThis workshop is a kickstart, hands-on tutorial on getting started with Apache Cassandra. It will cover Cassandra internals that will help you understand how Cassandra archives fast read/writes and how it handles machine/rack/data center failure.\nHour 1: Core concepts for Apache Cassandra\n \u2013 Introduction to Apache Cassandra\n \u2013 Data modeling\n \u2013 Fault tolerance\nHour 2:  Cassandra under the hood\n \u2013 Understand how Cassandra writes are so quick\n \u2013 Understanding Cassandra reads\n \u2013 Understand how Cassandra replication works including multi DC active active\n \u2013 Understanding compaction\nHour 3: Building an end-to-end customer event store in Java\n \u2013 Coding time! We\u2019ll go through how to build an application that can store and retrieve time series event data"}, "big-data-conference-uk-2015/public/schedule/detail/39703": {"room": "Buckingham Room - Palace Suite", "title": "Introducing Apache Flink: Fast and reliable data analytics in clusters", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39703", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/178179"], "timing": "17:05\u201317:45 Thursday,  7/05/2015", "abstract": "Description\nApache Flink (http://flink.incubator.apache.org) is an open source project undergoing incubation in the Apache Software Foundation. Flink creates a data analysis engine that is designed to match Hadoop in reliability and Spark in performance.\nThe project pushes the technology forward in many ways: Flink is compatible with the Hadoop ecosystem and runs on top of HDFS and YARN. Flink\u2019s programs are not executed directly but are optimized by Flink\u2019s cost-based optimizer similarly to what SQL engines do for relational algebra programs. This means that Flink applications require little (re-)configuration and little maintenance when the cluster characteristics change and the data evolves over time.\nFlink\u2019s runtime implements a unique approach to memory management, using in-memory execution as much as possible and very gracefully degrading to disk-based execution when memory is not enough. Flink introduces native closed-loop iteration operators, making graph analysis and machine learning applications very fast on the platform.\nFinally, Flink\u2019s runtime is a true data streaming engine, unifying batch processing and true stream processing in a single system. Flink is an active open source project with more than 70 contributors from industry and academia."}, "big-data-conference-uk-2015/public/schedule/detail/39709": {"room": "Blenheim Room - Palace Suite", "title": "D3.js Tutorial - D3 and interactive visualizations for everyone!", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39709", "topics": "Design", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/173073"], "timing": "13:30\u201317:00 Tuesday,  5/05/2015", "abstract": "Description\nMany organizations are turning to interactive data visualizations to communicate insights about data in order to connect data to business value. D3 is an award-winning data-visualization library that has gained considerable adoption among these organizations. It uses data to drive the creation and control of dynamic and interactive visualizations that range from simple charts to sophisticated animated data visualizations, general HTML layouts, and geographic projections.\nThis hands-on tutorial will allow attendees to master the D3 essentials to make the climb up D3\u2019s steep learning curve easier. We\u2019ll look at examples to illustrate how to create interactive data visualizations as well as best practices. Finally, there will be resources, examples, and exercises provided for continued study after the tutorial.\nAll attendees that want to follow along with exercises need a laptop with the Chrome browser installed and a text editor. Data sets, examples, and a cheat sheet will be provided. Awareness of basic HTML, CSS, JavaScript and how a web browser works will be helpful."}, "big-data-conference-uk-2015/public/schedule/detail/39931": {"room": "St. James / Regents", "title": "Turning streaming sushi into streaming data means happier customers", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39931", "topics": "IoT/Machine Data", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/154116"], "timing": "14:05\u201314:25 Wednesday,  6/05/2015", "abstract": "Description\nWhether your business is streaming sushi through a restaurant or streaming music through a smart phone, successfully competing for, and delighting, customers in today\u2019s hyper-competitive world requires a constant stream of fresh data.\nAs you look at shortening the collection and reporting intervals for key performance indicators from days to hours or even minutes, traditional batch data collection and ETL processes give way to real-time analytics and continuous data streams. The solution for SushiRo was Amazon Kinesis, the first fully managed service for streaming widely distributed data at massive scale.\nIn this presentation, Adi Krishnan will present a practical guide to streaming data in the cloud. The presentation will highlight the key challenges developers face when integrating high volume, highly distributed data into traditional and Hadoop-based application environments. The presentation will also review best practices for scaling, persisting, and delivering real-time data streams. It will highlight the architecture of SushiRo\u2019s real-time data infrastructure, and the impact that having a real-time operational dashboard in each store has had on customer satisfaction."}, "big-data-conference-uk-2015/public/schedule/detail/39624": {"room": "King's Suite - Sandringham", "title": "Friction-free ETL: Automating data transformation with Impala", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39624", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/143615"], "timing": "10:55\u201311:35 Wednesday,  6/05/2015", "abstract": "Description\nAs data is ingested into Apache Hadoop at an increasing rate from a diverse range of data sources, it is becoming more and more important for users that new data be accessible for analysis as quickly as possible\u2014because \u201cdata freshness\u201d can have a direct impact on business results.\nIn the traditional ETL process, raw data is transformed from the source into a target schema, possibly requiring flattening and condensing, and then loaded into an MPP DBMS. However, this approach has multiple drawbacks that make it unsuitable for real-time, \u201cat-source\u201d analytics\u2014for example, the \u201cETL lag\u201d reduces data freshness, and the inherent complexity of the process makes it costly to deploy and maintain, and reduces the speed at which new analytic applications can be introduced.\nIn this talk, attendees will learn about Impala\u2019s approach to on-the-fly, automatic data transformation, which in conjunction with the ability to handle nested structures such as JSON and XML documents, addresses the needs of at-source analytics\u2014including direct querying of your input schema, immediate querying of data as it lands in HDFS, and high performance on par with specialized engines. This performance level is attained in spite of the most challenging and diverse input formats, which are addressed through an automated background conversion process into Parquet, the high-performance, open source columnar format that has been widely adopted across the Hadoop ecosystem.\nIn this talk, attendees will learn about Impala\u2019s upcoming features that will enable at-source analytics: support for nested structures such as JSON and XML documents, which allows direct querying of the source schema; automated background file format conversion into Parquet, the high-performance, open source columnar format that has been widely adopted across the Hadoop ecosystem; and automated creation of declaratively-specified derived data for simplified data cleansing and transformation."}, "big-data-conference-uk-2015/public/schedule/detail/39627": {"room": "King's Suite - Sandringham", "title": "The Future of Apache Hadoop Security", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39627", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/138919"], "timing": "13:45\u201314:25 Thursday,  7/05/2015", "abstract": "Description\nAs the volume of data and number of applications moving to Apache Hadoop has increased, so has the need to secure that data and those applications. In this presentation, we\u2019ll take a brief look at where Hadoop security is today and then peer into the future to see where Hadoop security is headed. Along the way, we\u2019ll visit new projects such as Apache Sentry (incubating) and Apache Knox (incubating) as well as initiatives such as Project Rhino. We\u2019ll see how all of this activity is making good on the promise of Hadoop as the future of data management."}, "big-data-conference-uk-2015/public/schedule/detail/39626": {"room": "King's Suite - Balmoral", "title": "Building an Apache Hadoop data application", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39626", "topics": "Hadoop Platform", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/43459", "/big-data-conference-uk-2015/public/schedule/speaker/138919", "/big-data-conference-uk-2015/public/schedule/speaker/183010"], "timing": "13:30\u201317:00 Tuesday,  5/05/2015", "abstract": "Description\nIn the second (afternoon) half of the Architecture Day tutorial, attendees will build a data application from the ground up. The application will ingest streaming user data (like web clicks), and using tools and APIs in the Kite SDK, transform and store the data in Hadoop in a form that is readily consumable with Hadoop tools like Impala and Spark.\nAs a part of the tutorial we will demonstrate how Kite codifies the best practices from the Hadoop Architecture Day morning session."}, "big-data-conference-uk-2015/public/schedule/detail/39779": {"room": "King's Suite - Balmoral", "title": "What we are made of: Analyzing the human genome with SQL", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39779", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/164036"], "timing": "14:05\u201314:25 Wednesday,  6/05/2015", "abstract": "Description\nHow big is the human genome? What tools can we use to manage and understand it? Turns out the same tools used for traditional purposes (Hadoop, Spark, BigQuery and SQL) can be applied to genomics. In this session we\u2019ll introduce the basics of managing genomes with our favorite big data tools, and draw parallels with more traditional use cases like analyzing view logs.\nTakeaways:\n- The same SQL constructs that help us understand the world, can help us understand the basic fabrics of life.\n- Live demos with Hadoop, Spark, and BigQuery will highlight how we can leverage the latest in Google tools and services to accelerate data insights, bringing them from batch to real interactive time."}, "big-data-conference-uk-2015/public/schedule/detail/39836": {"room": "King's Suite - Balmoral", "title": "Users love Spark. Does Spark love (multiple) users?", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39836", "topics": "Data Science", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/190455"], "timing": "14:55\u201315:15 Thursday,  7/05/2015", "abstract": "Description\nApache Spark is a powerful, unified data processing engine offering a number of APIs, from batch/SQL over streaming to manipulations over graphs. The core architecture of Spark has not necessarily been designed with a multi-user environment in mind. We will review existing and emerging approaches how to use Spark in multi-user environments, such as the Tachyon project."}, "big-data-conference-uk-2015/public/schedule/detail/39809": {"room": "Buckingham Room - Palace Suite", "title": "Search evolved: Unraveling your data", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39809", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/178255"], "timing": "10:55\u201311:35 Thursday,  7/05/2015", "abstract": "Description\nWhen people hear the word \u201csearch,\u201d they picture a box that you type words into to answer a question. However, even when it looks very simple, search \u2013 and making sense of the data that comes back \u2013 is much more complex. For businesses, it\u2019s critical to have sophisticated tools that unlock the meaning behind whatever is typed into that box, and present the analysis in a clean, clear way that decision-makers who aren\u2019t data experts can understand. Unraveling the data to get to this clarity is much harder than it might seem.\nIn this talk, Shay Banon, creator of Elasticsearch, will go over how search has evolved to be the only technology that can serve as the backbone for today\u2019s analytics demands. The presentation will dive into the importance of being able to triangulate unstructured data, such as free-text, with structured data, such as time-stamped events and metadata, with aggregations to help businesses ask the right questions of their data.\nThis session will also highlight how a versatile, agile search and analytics platform can give shape to data, and uncover the \u201cuncommonly common\u201d trends within, providing businesses real-time insights and setting them up to make the right data-driven decisions."}, "big-data-conference-uk-2015/public/schedule/detail/40017": {"room": "Buckingham Room - Palace Suite", "title": "Apache Spark: What's new; what's coming", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/40017", "topics": "Hadoop & Beyond", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/152591"], "timing": "11:45\u201312:25 Wednesday,  6/05/2015", "abstract": "Description\nThe last year has seen significant growth in the Spark community, with several major releases (Spark 1.0, 1.1, and 1.2), new standard libraries (Spark MLlib and Spark SQL), and an ecosystem of community projects based on Spark.\nThis talk will provide an overview of Apache Spark and its current feature set, adoption, and use cases. It will then cover recent feature additions to Apache Spark such as elastic scaling support, new algorithms in MLlib, and the Spark SQL datasources API. It will also outline the Spark roadmap for upcoming months. Since this talk is not until May, the specific roadmap details will likely be determined close to the talk itself.\nThis talk is being submitted by Patrick Wendell, release manager of Spark 1.0, 1.1, and 1.2."}, "big-data-conference-uk-2015/public/schedule/detail/39965": {"room": "St. James / Regents", "title": "Steady UX: Balancing personalisation and privacy to create understanding and trust", "url": "http://strataconf.com/big-data-conference-uk-2015/public/schedule/detail/39965", "topics": "Privacy, Law, & Ethics", "speaker_urls": ["/big-data-conference-uk-2015/public/schedule/speaker/137780"], "timing": "14:35\u201315:15 Thursday,  7/05/2015", "abstract": "Description\nThe last few years have seen the unleashing of a small army of ubiquitous sensors and massive behavioural data sets, and we are only seeing a glimpse of the Internet of Everything to come. Combined with our ever-increasing capability to make sense of said data, the internet probably knows the \u2018recent\u2019 me better than my best friend.\n\u201cNo other Apple device has ever been so connected to the wearer, it\u2019s important to be mindful of this connection,\u201d the draft Human Interface Design Guidelines for the Apple Watch read.\nThis connection we have with our smart watches, mobile phones, health trackers, and soon cars, is no longer merely about exchanging data back and forth. This new human-computer-connection is about that other type of connecting. Connecting, between human and machine, now revolves around values which we normally find in human-to-human relationships: understanding and trust.\nWe expect that these devices do the computing effort to understand us; smart personalisation. We also expect that we can trust them to keep what they learn about us to themselves \u2013 respecting our privacy.\nIt is well-argued that if we want increased personalisation and a better user experience, we have no choice but to give up our privacy. However, having to choose between good UX and personalisation or privacy is a false dilemma. Businesses can deliver a grand user experience and tremendous value if they safeguard their users\u2019 privacy and security \u2013 if they start with the idea that privacy is a fundamental component of the product experience.\nWith the shaping of the Internet of Everything, our designer roles and responsibilities are undergoing a swift and thorough transformation. User experience design has been extended to address all aspects of a product or service as perceived by its users. However, credibility has always been essential for a positive user experience; and taking responsibility for keeping safe personal data, and being trustworthy, is definitely part of that perception of our product and services\nWith personal data privacy a concern for around 75% of consumers, and with a more strict European law coming up, we owe it to both our users and the companies we work for to actively think about privacy \u2013 and how to implement it in their flows and designs \u2013 from start to finish.\nAs designers, we are already used to aligning humans and technology, as well as business and user needs. We have plenty of the skills, experience, and even stakeholder-connections needed to make privacy count from early on in the project.\n\nUnderstand the end goal \u2013 the \u2018why?\u2019\nThere are rules, guidelines and tool kits.\nYou can not do it alone.\nLess is more.\nYet the devil is in the details.\nHonest communications are mission-critical\n\nThese are the six basic concepts that apply to UX design, as well as data protection and privacy, that will be covered in this talk, as well as plenty of user experience design opportunities to offer both understanding and trust."}}